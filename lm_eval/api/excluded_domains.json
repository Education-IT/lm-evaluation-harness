{
    "www.quora.com": {
        "count": 16820,
        "arc_challenge": 423,
        "arc_easy": 711,
        "headqa_en": 50,
        "webqs": 32,
        "gsm8k": 517,
        "mmlu_moral_disputes": 12,
        "mmlu_moral_scenarios": 597,
        "mmlu_prehistory": 16,
        "mmlu_high_school_world_history": 9,
        "mmlu_professional_law": 305,
        "mmlu_philosophy": 30,
        "mmlu_logical_fallacies": 21,
        "mmlu_formal_logic": 18,
        "mmlu_high_school_european_history": 3,
        "mmlu_world_religions": 16,
        "mmlu_high_school_geography": 15,
        "mmlu_public_relations": 5,
        "mmlu_high_school_psychology": 53,
        "mmlu_professional_psychology": 58,
        "mmlu_high_school_microeconomics": 19,
        "mmlu_high_school_government_and_politics": 5,
        "mmlu_high_school_macroeconomics": 9,
        "mmlu_security_studies": 5,
        "mmlu_human_sexuality": 11,
        "mmlu_sociology": 9,
        "mmlu_us_foreign_policy": 3,
        "mmlu_human_aging": 23,
        "mmlu_miscellaneous": 120,
        "mmlu_marketing": 7,
        "mmlu_business_ethics": 4,
        "mmlu_virology": 1,
        "mmlu_professional_accounting": 1,
        "mmlu_medical_genetics": 1,
        "mmlu_college_medicine": 20,
        "mmlu_management": 8,
        "mmlu_nutrition": 3,
        "mmlu_clinical_knowledge": 10,
        "mmlu_professional_medicine": 5,
        "mmlu_high_school_statistics": 20,
        "mmlu_abstract_algebra": 10,
        "mmlu_college_biology": 11,
        "mmlu_high_school_mathematics": 83,
        "mmlu_computer_security": 7,
        "mmlu_high_school_biology": 22,
        "mmlu_anatomy": 2,
        "mmlu_high_school_chemistry": 54,
        "mmlu_machine_learning": 7,
        "mmlu_electrical_engineering": 34,
        "mmlu_elementary_mathematics": 74,
        "mmlu_college_mathematics": 32,
        "mmlu_college_physics": 43,
        "mmlu_college_computer_science": 21,
        "mmlu_conceptual_physics": 164,
        "mmlu_high_school_physics": 77,
        "mmlu_college_chemistry": 14,
        "mmlu_high_school_computer_science": 15,
        "mmlu_astronomy": 55,
        "gpqa_diamond_cot_n_shot": 14,
        "gpqa_main_cot_n_shot": 25,
        "gpqa_extended_cot_n_shot": 31,
        "gpqa_extended_n_shot": 30,
        "gpqa_main_n_shot": 24,
        "gpqa_diamond_n_shot": 14,
        "gpqa_extended_generative_n_shot": 30,
        "gpqa_diamond_generative_n_shot": 14,
        "gpqa_main_generative_n_shot": 25,
        "gpqa_extended_zeroshot": 30,
        "gpqa_main_zeroshot": 25,
        "gpqa_diamond_zeroshot": 15,
        "gpqa_diamond_cot_zeroshot": 14,
        "gpqa_extended_cot_zeroshot": 33,
        "gpqa_main_cot_zeroshot": 28,
        "sciq": 155,
        "agieval_sat_math": 13,
        "agieval_math": 414,
        "agieval_lsat_lr": 4,
        "agieval_logiqa_en": 111,
        "agieval_gaokao_english": 71,
        "agieval_aqua_rat": 117,
        "commonsense_qa": 761,
        "toxigen": 647,
        "arithmetic_3da": 85,
        "arithmetic_3ds": 89,
        "arithmetic_4da": 104,
        "arithmetic_2ds": 49,
        "arithmetic_5ds": 501,
        "arithmetic_5da": 377,
        "arithmetic_1dc": 810,
        "arithmetic_4ds": 127,
        "arithmetic_2dm": 85,
        "arithmetic_2da": 109,
        "nq_open": 156,
        "triviaqa": 1277,
        "bbh_cot_fewshot_word_sorting": 3,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 6,
        "bbh_cot_fewshot_temporal_sequences": 34,
        "bbh_cot_fewshot_sports_understanding": 2,
        "bbh_cot_fewshot_snarks": 108,
        "groundcocoa": 6353
    },
    "huggingface.co": {
        "count": 15497,
        "arc_challenge": 154,
        "arc_easy": 26,
        "headqa_en": 8,
        "gsm8k": 1503,
        "arc_challenge_mt_pl": 15,
        "mmlu_jurisprudence": 20,
        "mmlu_moral_disputes": 16,
        "mmlu_moral_scenarios": 664,
        "mmlu_prehistory": 19,
        "mmlu_high_school_world_history": 306,
        "mmlu_professional_law": 183,
        "mmlu_philosophy": 15,
        "mmlu_high_school_us_history": 440,
        "mmlu_logical_fallacies": 75,
        "mmlu_formal_logic": 154,
        "mmlu_high_school_european_history": 310,
        "mmlu_international_law": 2,
        "mmlu_world_religions": 13,
        "mmlu_high_school_geography": 20,
        "mmlu_public_relations": 42,
        "mmlu_high_school_psychology": 100,
        "mmlu_professional_psychology": 81,
        "mmlu_high_school_microeconomics": 8,
        "mmlu_high_school_government_and_politics": 4,
        "mmlu_high_school_macroeconomics": 10,
        "mmlu_security_studies": 14,
        "mmlu_human_sexuality": 27,
        "mmlu_sociology": 8,
        "mmlu_econometrics": 81,
        "mmlu_human_aging": 22,
        "mmlu_miscellaneous": 28,
        "mmlu_marketing": 67,
        "mmlu_business_ethics": 98,
        "mmlu_professional_accounting": 71,
        "mmlu_medical_genetics": 16,
        "mmlu_global_facts": 4,
        "mmlu_college_medicine": 45,
        "mmlu_management": 10,
        "mmlu_nutrition": 2,
        "mmlu_clinical_knowledge": 5,
        "mmlu_professional_medicine": 55,
        "mmlu_high_school_statistics": 13,
        "mmlu_abstract_algebra": 23,
        "mmlu_college_biology": 12,
        "mmlu_high_school_mathematics": 134,
        "mmlu_computer_security": 29,
        "mmlu_high_school_biology": 2,
        "mmlu_anatomy": 2,
        "mmlu_high_school_chemistry": 41,
        "mmlu_machine_learning": 70,
        "mmlu_electrical_engineering": 1,
        "mmlu_elementary_mathematics": 90,
        "mmlu_college_mathematics": 21,
        "mmlu_college_physics": 36,
        "mmlu_college_computer_science": 56,
        "mmlu_conceptual_physics": 17,
        "mmlu_high_school_physics": 32,
        "mmlu_college_chemistry": 75,
        "mmlu_high_school_computer_science": 49,
        "mmlu_astronomy": 12,
        "gpqa_diamond_cot_n_shot": 152,
        "gpqa_main_cot_n_shot": 212,
        "gpqa_extended_cot_n_shot": 219,
        "gpqa_extended_n_shot": 220,
        "gpqa_main_n_shot": 214,
        "gpqa_diamond_n_shot": 154,
        "gpqa_extended_generative_n_shot": 219,
        "gpqa_diamond_generative_n_shot": 154,
        "gpqa_main_generative_n_shot": 210,
        "gpqa_extended_zeroshot": 215,
        "gpqa_main_zeroshot": 171,
        "gpqa_diamond_zeroshot": 147,
        "gpqa_diamond_cot_zeroshot": 149,
        "gpqa_extended_cot_zeroshot": 213,
        "gpqa_main_cot_zeroshot": 208,
        "agieval_sat_math": 86,
        "agieval_sat_en_without_passage": 55,
        "agieval_math": 859,
        "agieval_lsat_rc": 19,
        "agieval_lsat_lr": 24,
        "agieval_lsat_ar": 110,
        "agieval_logiqa_en": 119,
        "agieval_gaokao_english": 121,
        "agieval_aqua_rat": 271,
        "commonsense_qa": 1,
        "toxigen": 41,
        "arithmetic_4da": 1,
        "arithmetic_5ds": 13,
        "arithmetic_5da": 9,
        "triviaqa": 1292,
        "bbh_cot_fewshot_word_sorting": 211,
        "bbh_cot_fewshot_web_of_lies": 501,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 767,
        "bbh_cot_fewshot_tracking_shuffled_objects_seven_objects": 524,
        "bbh_cot_fewshot_tracking_shuffled_objects_five_objects": 634,
        "bbh_cot_fewshot_temporal_sequences": 20,
        "bbh_cot_fewshot_sports_understanding": 703,
        "bbh_cot_fewshot_snarks": 29,
        "bbh_cot_fewshot_salient_translation_error_detection": 500,
        "groundcocoa": 110,
        "polemo2_out": 43,
        "polemo2_in": 121
    },
    "quizlet.com": {
        "count": 10069,
        "arc_challenge": 776,
        "arc_easy": 1178,
        "headqa_en": 120,
        "gsm8k": 23,
        "mmlu_jurisprudence": 28,
        "mmlu_moral_disputes": 282,
        "mmlu_moral_scenarios": 32,
        "mmlu_prehistory": 237,
        "mmlu_high_school_world_history": 46,
        "mmlu_professional_law": 1057,
        "mmlu_philosophy": 373,
        "mmlu_high_school_us_history": 28,
        "mmlu_logical_fallacies": 41,
        "mmlu_formal_logic": 7,
        "mmlu_high_school_european_history": 25,
        "mmlu_international_law": 10,
        "mmlu_world_religions": 13,
        "mmlu_high_school_geography": 156,
        "mmlu_public_relations": 72,
        "mmlu_high_school_psychology": 731,
        "mmlu_professional_psychology": 337,
        "mmlu_high_school_microeconomics": 243,
        "mmlu_high_school_government_and_politics": 132,
        "mmlu_high_school_macroeconomics": 244,
        "mmlu_security_studies": 40,
        "mmlu_human_sexuality": 23,
        "mmlu_sociology": 14,
        "mmlu_us_foreign_policy": 15,
        "mmlu_econometrics": 94,
        "mmlu_human_aging": 35,
        "mmlu_miscellaneous": 215,
        "mmlu_marketing": 205,
        "mmlu_business_ethics": 78,
        "mmlu_virology": 23,
        "mmlu_professional_accounting": 546,
        "mmlu_medical_genetics": 34,
        "mmlu_global_facts": 3,
        "mmlu_college_medicine": 49,
        "mmlu_management": 28,
        "mmlu_nutrition": 106,
        "mmlu_clinical_knowledge": 36,
        "mmlu_professional_medicine": 161,
        "mmlu_high_school_statistics": 215,
        "mmlu_abstract_algebra": 24,
        "mmlu_college_biology": 116,
        "mmlu_high_school_mathematics": 8,
        "mmlu_computer_security": 27,
        "mmlu_high_school_biology": 364,
        "mmlu_anatomy": 66,
        "mmlu_high_school_chemistry": 72,
        "mmlu_machine_learning": 8,
        "mmlu_electrical_engineering": 1,
        "mmlu_elementary_mathematics": 95,
        "mmlu_college_mathematics": 3,
        "mmlu_college_physics": 10,
        "mmlu_college_computer_science": 20,
        "mmlu_conceptual_physics": 323,
        "mmlu_high_school_physics": 113,
        "mmlu_college_chemistry": 8,
        "mmlu_high_school_computer_science": 167,
        "mmlu_astronomy": 90,
        "gpqa_main_cot_n_shot": 4,
        "gpqa_extended_cot_n_shot": 6,
        "gpqa_extended_n_shot": 5,
        "gpqa_main_n_shot": 4,
        "gpqa_extended_generative_n_shot": 5,
        "gpqa_main_generative_n_shot": 4,
        "gpqa_extended_zeroshot": 5,
        "gpqa_main_zeroshot": 4,
        "gpqa_extended_cot_zeroshot": 5,
        "gpqa_main_cot_zeroshot": 4,
        "sciq": 55,
        "agieval_sat_math": 26,
        "agieval_sat_en": 4,
        "agieval_sat_en_without_passage": 19,
        "agieval_math": 9,
        "agieval_lsat_rc": 8,
        "agieval_lsat_lr": 25,
        "agieval_lsat_ar": 37,
        "agieval_logiqa_en": 3,
        "agieval_gaokao_english": 8,
        "agieval_aqua_rat": 5,
        "commonsense_qa": 7,
        "toxigen": 2,
        "arithmetic_3da": 9,
        "arithmetic_3ds": 1,
        "arithmetic_4da": 3,
        "arithmetic_5da": 1,
        "nq_open": 101,
        "triviaqa": 72,
        "bbh_cot_fewshot_word_sorting": 1,
        "bbh_cot_fewshot_sports_understanding": 1
    },
    "brainly.com": {
        "count": 7297,
        "arc_challenge": 561,
        "arc_easy": 1027,
        "headqa_en": 104,
        "gsm8k": 49,
        "mmlu_jurisprudence": 14,
        "mmlu_moral_disputes": 45,
        "mmlu_prehistory": 19,
        "mmlu_high_school_world_history": 12,
        "mmlu_professional_law": 132,
        "mmlu_philosophy": 89,
        "mmlu_high_school_us_history": 15,
        "mmlu_logical_fallacies": 6,
        "mmlu_formal_logic": 16,
        "mmlu_high_school_european_history": 6,
        "mmlu_world_religions": 3,
        "mmlu_high_school_geography": 62,
        "mmlu_public_relations": 3,
        "mmlu_high_school_psychology": 342,
        "mmlu_professional_psychology": 95,
        "mmlu_high_school_microeconomics": 144,
        "mmlu_high_school_government_and_politics": 81,
        "mmlu_high_school_macroeconomics": 130,
        "mmlu_security_studies": 10,
        "mmlu_human_sexuality": 3,
        "mmlu_sociology": 13,
        "mmlu_us_foreign_policy": 1,
        "mmlu_econometrics": 15,
        "mmlu_human_aging": 16,
        "mmlu_miscellaneous": 82,
        "mmlu_marketing": 32,
        "mmlu_business_ethics": 8,
        "mmlu_virology": 3,
        "mmlu_professional_accounting": 215,
        "mmlu_medical_genetics": 5,
        "mmlu_global_facts": 1,
        "mmlu_college_medicine": 16,
        "mmlu_management": 9,
        "mmlu_nutrition": 30,
        "mmlu_clinical_knowledge": 12,
        "mmlu_professional_medicine": 115,
        "mmlu_high_school_statistics": 135,
        "mmlu_abstract_algebra": 7,
        "mmlu_college_biology": 69,
        "mmlu_high_school_mathematics": 189,
        "mmlu_computer_security": 9,
        "mmlu_high_school_biology": 221,
        "mmlu_anatomy": 37,
        "mmlu_high_school_chemistry": 86,
        "mmlu_machine_learning": 13,
        "mmlu_electrical_engineering": 7,
        "mmlu_elementary_mathematics": 323,
        "mmlu_college_mathematics": 10,
        "mmlu_college_physics": 32,
        "mmlu_college_computer_science": 12,
        "mmlu_conceptual_physics": 176,
        "mmlu_high_school_physics": 107,
        "mmlu_college_chemistry": 31,
        "mmlu_high_school_computer_science": 116,
        "mmlu_astronomy": 75,
        "gpqa_diamond_cot_n_shot": 5,
        "gpqa_main_cot_n_shot": 6,
        "gpqa_extended_cot_n_shot": 5,
        "gpqa_extended_n_shot": 2,
        "gpqa_main_n_shot": 2,
        "gpqa_diamond_n_shot": 2,
        "gpqa_extended_generative_n_shot": 2,
        "gpqa_diamond_generative_n_shot": 2,
        "gpqa_main_generative_n_shot": 4,
        "gpqa_extended_zeroshot": 4,
        "gpqa_main_zeroshot": 2,
        "gpqa_diamond_zeroshot": 3,
        "gpqa_diamond_cot_zeroshot": 2,
        "gpqa_extended_cot_zeroshot": 2,
        "gpqa_main_cot_zeroshot": 3,
        "sciq": 95,
        "agieval_sat_math": 79,
        "agieval_sat_en": 8,
        "agieval_sat_en_without_passage": 22,
        "agieval_math": 342,
        "agieval_lsat_lr": 2,
        "agieval_lsat_ar": 6,
        "agieval_aqua_rat": 3,
        "commonsense_qa": 12,
        "toxigen": 2,
        "arithmetic_3da": 99,
        "arithmetic_3ds": 222,
        "arithmetic_4da": 15,
        "arithmetic_2ds": 186,
        "arithmetic_5ds": 2,
        "arithmetic_5da": 8,
        "arithmetic_1dc": 161,
        "arithmetic_4ds": 44,
        "arithmetic_2dm": 461,
        "arithmetic_2da": 56,
        "nq_open": 103,
        "triviaqa": 116,
        "bbh_cot_fewshot_word_sorting": 1,
        "bbh_cot_fewshot_snarks": 10
    },
    "www.reddit.com": {
        "count": 6644,
        "mmlu_professional_law": 28,
        "mmlu_professional_accounting": 22,
        "mmlu_nutrition": 12,
        "gpqa_diamond_cot_n_shot": 1,
        "gpqa_main_cot_n_shot": 3,
        "gpqa_extended_cot_n_shot": 6,
        "gpqa_extended_n_shot": 6,
        "gpqa_main_n_shot": 3,
        "gpqa_diamond_n_shot": 1,
        "gpqa_extended_generative_n_shot": 6,
        "gpqa_diamond_generative_n_shot": 1,
        "gpqa_main_generative_n_shot": 3,
        "gpqa_extended_zeroshot": 7,
        "gpqa_main_zeroshot": 2,
        "gpqa_diamond_zeroshot": 1,
        "gpqa_diamond_cot_zeroshot": 1,
        "gpqa_extended_cot_zeroshot": 6,
        "gpqa_main_cot_zeroshot": 4,
        "sciq": 12,
        "agieval_sat_math": 3,
        "agieval_sat_en_without_passage": 6,
        "agieval_math": 15,
        "agieval_lsat_lr": 2,
        "agieval_lsat_ar": 17,
        "agieval_logiqa_en": 21,
        "agieval_gaokao_english": 37,
        "agieval_aqua_rat": 4,
        "commonsense_qa": 518,
        "toxigen": 532,
        "arithmetic_3da": 92,
        "arithmetic_3ds": 42,
        "arithmetic_4da": 3,
        "arithmetic_2ds": 8,
        "arithmetic_5ds": 4,
        "arithmetic_5da": 8,
        "arithmetic_1dc": 76,
        "arithmetic_4ds": 15,
        "arithmetic_2dm": 36,
        "arithmetic_2da": 15,
        "nq_open": 160,
        "triviaqa": 463,
        "bbh_cot_fewshot_word_sorting": 2,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 2,
        "bbh_cot_fewshot_temporal_sequences": 3,
        "bbh_cot_fewshot_snarks": 150,
        "groundcocoa": 4280,
        "polemo2_out": 2,
        "polemo2_in": 3
    },
    "github.com": {
        "count": 4154,
        "arc_challenge": 30,
        "arc_easy": 13,
        "webqs": 2,
        "gsm8k": 1056,
        "mmlu_moral_scenarios": 163,
        "mmlu_high_school_world_history": 67,
        "mmlu_professional_law": 14,
        "mmlu_philosophy": 22,
        "mmlu_high_school_us_history": 48,
        "mmlu_formal_logic": 14,
        "mmlu_high_school_european_history": 46,
        "mmlu_world_religions": 6,
        "mmlu_professional_psychology": 1,
        "mmlu_human_sexuality": 1,
        "mmlu_business_ethics": 2,
        "mmlu_college_medicine": 1,
        "mmlu_professional_medicine": 13,
        "mmlu_high_school_statistics": 4,
        "mmlu_abstract_algebra": 4,
        "mmlu_high_school_mathematics": 27,
        "mmlu_computer_security": 9,
        "mmlu_anatomy": 4,
        "mmlu_machine_learning": 2,
        "mmlu_elementary_mathematics": 5,
        "mmlu_college_computer_science": 2,
        "mmlu_high_school_computer_science": 3,
        "gpqa_diamond_cot_n_shot": 11,
        "gpqa_main_cot_n_shot": 13,
        "gpqa_extended_cot_n_shot": 13,
        "gpqa_extended_n_shot": 13,
        "gpqa_main_n_shot": 13,
        "gpqa_diamond_n_shot": 11,
        "gpqa_extended_generative_n_shot": 13,
        "gpqa_diamond_generative_n_shot": 11,
        "gpqa_main_generative_n_shot": 12,
        "gpqa_extended_zeroshot": 12,
        "gpqa_main_zeroshot": 12,
        "gpqa_diamond_zeroshot": 9,
        "gpqa_diamond_cot_zeroshot": 9,
        "gpqa_extended_cot_zeroshot": 11,
        "gpqa_main_cot_zeroshot": 11,
        "sciq": 2,
        "agieval_sat_math": 16,
        "agieval_sat_en_without_passage": 1,
        "agieval_math": 111,
        "agieval_lsat_lr": 2,
        "agieval_logiqa_en": 248,
        "agieval_aqua_rat": 263,
        "qasper_bool": 20,
        "commonsense_qa": 1,
        "toxigen": 4,
        "arithmetic_3da": 3,
        "arithmetic_3ds": 1,
        "arithmetic_4da": 1,
        "arithmetic_5ds": 718,
        "arithmetic_5da": 26,
        "arithmetic_4ds": 5,
        "triviaqa": 64,
        "bbh_cot_fewshot_word_sorting": 76,
        "bbh_cot_fewshot_web_of_lies": 37,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 478,
        "bbh_cot_fewshot_tracking_shuffled_objects_five_objects": 269,
        "bbh_cot_fewshot_temporal_sequences": 11,
        "bbh_cot_fewshot_sports_understanding": 10,
        "groundcocoa": 54
    },
    "www.chegg.com": {
        "count": 3998,
        "arc_challenge": 51,
        "arc_easy": 58,
        "headqa_en": 64,
        "gsm8k": 16,
        "mmlu_jurisprudence": 18,
        "mmlu_moral_disputes": 39,
        "mmlu_prehistory": 9,
        "mmlu_high_school_world_history": 2,
        "mmlu_professional_law": 60,
        "mmlu_philosophy": 67,
        "mmlu_logical_fallacies": 11,
        "mmlu_formal_logic": 49,
        "mmlu_high_school_european_history": 6,
        "mmlu_international_law": 15,
        "mmlu_high_school_geography": 8,
        "mmlu_high_school_psychology": 25,
        "mmlu_professional_psychology": 29,
        "mmlu_high_school_microeconomics": 127,
        "mmlu_high_school_government_and_politics": 16,
        "mmlu_high_school_macroeconomics": 95,
        "mmlu_security_studies": 9,
        "mmlu_human_sexuality": 5,
        "mmlu_sociology": 25,
        "mmlu_econometrics": 95,
        "mmlu_human_aging": 17,
        "mmlu_miscellaneous": 30,
        "mmlu_marketing": 116,
        "mmlu_business_ethics": 34,
        "mmlu_virology": 18,
        "mmlu_professional_accounting": 276,
        "mmlu_medical_genetics": 21,
        "mmlu_global_facts": 5,
        "mmlu_college_medicine": 43,
        "mmlu_management": 29,
        "mmlu_nutrition": 70,
        "mmlu_clinical_knowledge": 42,
        "mmlu_professional_medicine": 26,
        "mmlu_high_school_statistics": 152,
        "mmlu_abstract_algebra": 32,
        "mmlu_college_biology": 72,
        "mmlu_high_school_mathematics": 30,
        "mmlu_computer_security": 18,
        "mmlu_high_school_biology": 173,
        "mmlu_anatomy": 21,
        "mmlu_high_school_chemistry": 69,
        "mmlu_machine_learning": 31,
        "mmlu_electrical_engineering": 18,
        "mmlu_elementary_mathematics": 108,
        "mmlu_college_mathematics": 45,
        "mmlu_college_physics": 130,
        "mmlu_college_computer_science": 45,
        "mmlu_conceptual_physics": 164,
        "mmlu_high_school_physics": 72,
        "mmlu_college_chemistry": 67,
        "mmlu_high_school_computer_science": 30,
        "mmlu_astronomy": 48,
        "gpqa_diamond_cot_n_shot": 17,
        "gpqa_main_cot_n_shot": 56,
        "gpqa_extended_cot_n_shot": 61,
        "gpqa_extended_n_shot": 61,
        "gpqa_main_n_shot": 55,
        "gpqa_diamond_n_shot": 17,
        "gpqa_extended_generative_n_shot": 61,
        "gpqa_diamond_generative_n_shot": 17,
        "gpqa_main_generative_n_shot": 56,
        "gpqa_extended_zeroshot": 62,
        "gpqa_main_zeroshot": 50,
        "gpqa_diamond_zeroshot": 17,
        "gpqa_diamond_cot_zeroshot": 17,
        "gpqa_extended_cot_zeroshot": 62,
        "gpqa_main_cot_zeroshot": 57,
        "sciq": 15,
        "agieval_sat_math": 35,
        "agieval_math": 43,
        "agieval_lsat_lr": 1,
        "agieval_aqua_rat": 5,
        "commonsense_qa": 2,
        "toxigen": 1,
        "arithmetic_3da": 10,
        "arithmetic_3ds": 31,
        "arithmetic_2ds": 32,
        "arithmetic_5ds": 1,
        "arithmetic_5da": 1,
        "arithmetic_1dc": 1,
        "arithmetic_4ds": 9,
        "arithmetic_2dm": 172,
        "arithmetic_2da": 1,
        "nq_open": 16,
        "triviaqa": 5
    },
    "www.coursehero.com": {
        "count": 3092,
        "arc_challenge": 72,
        "arc_easy": 80,
        "headqa_en": 3,
        "gsm8k": 22,
        "mmlu_jurisprudence": 16,
        "mmlu_moral_disputes": 19,
        "mmlu_moral_scenarios": 142,
        "mmlu_prehistory": 11,
        "mmlu_high_school_world_history": 202,
        "mmlu_professional_law": 532,
        "mmlu_philosophy": 81,
        "mmlu_high_school_us_history": 26,
        "mmlu_logical_fallacies": 15,
        "mmlu_formal_logic": 5,
        "mmlu_high_school_european_history": 53,
        "mmlu_international_law": 3,
        "mmlu_world_religions": 1,
        "mmlu_high_school_geography": 2,
        "mmlu_public_relations": 56,
        "mmlu_high_school_psychology": 104,
        "mmlu_professional_psychology": 17,
        "mmlu_high_school_microeconomics": 14,
        "mmlu_high_school_government_and_politics": 6,
        "mmlu_high_school_macroeconomics": 18,
        "mmlu_security_studies": 10,
        "mmlu_human_sexuality": 4,
        "mmlu_sociology": 5,
        "mmlu_us_foreign_policy": 1,
        "mmlu_econometrics": 84,
        "mmlu_human_aging": 10,
        "mmlu_miscellaneous": 29,
        "mmlu_marketing": 229,
        "mmlu_business_ethics": 72,
        "mmlu_virology": 10,
        "mmlu_professional_accounting": 271,
        "mmlu_global_facts": 7,
        "mmlu_college_medicine": 3,
        "mmlu_management": 31,
        "mmlu_nutrition": 15,
        "mmlu_professional_medicine": 110,
        "mmlu_high_school_statistics": 63,
        "mmlu_abstract_algebra": 2,
        "mmlu_college_biology": 10,
        "mmlu_high_school_mathematics": 11,
        "mmlu_computer_security": 20,
        "mmlu_high_school_biology": 18,
        "mmlu_anatomy": 7,
        "mmlu_high_school_chemistry": 9,
        "mmlu_machine_learning": 28,
        "mmlu_electrical_engineering": 7,
        "mmlu_elementary_mathematics": 42,
        "mmlu_college_mathematics": 1,
        "mmlu_college_physics": 2,
        "mmlu_college_computer_science": 10,
        "mmlu_conceptual_physics": 17,
        "mmlu_high_school_physics": 21,
        "mmlu_college_chemistry": 6,
        "mmlu_high_school_computer_science": 69,
        "mmlu_astronomy": 12,
        "gpqa_diamond_cot_n_shot": 3,
        "gpqa_main_cot_n_shot": 3,
        "gpqa_extended_cot_n_shot": 3,
        "gpqa_extended_n_shot": 3,
        "gpqa_main_n_shot": 3,
        "gpqa_diamond_n_shot": 3,
        "gpqa_extended_generative_n_shot": 3,
        "gpqa_diamond_generative_n_shot": 3,
        "gpqa_main_generative_n_shot": 3,
        "gpqa_extended_zeroshot": 3,
        "gpqa_main_zeroshot": 3,
        "gpqa_diamond_zeroshot": 3,
        "gpqa_diamond_cot_zeroshot": 3,
        "gpqa_extended_cot_zeroshot": 3,
        "gpqa_main_cot_zeroshot": 3,
        "sciq": 3,
        "agieval_sat_math": 14,
        "agieval_sat_en_without_passage": 118,
        "agieval_math": 16,
        "agieval_lsat_rc": 26,
        "agieval_lsat_lr": 22,
        "agieval_lsat_ar": 56,
        "agieval_logiqa_en": 1,
        "agieval_gaokao_english": 8,
        "agieval_aqua_rat": 17,
        "commonsense_qa": 2,
        "toxigen": 1,
        "arithmetic_5ds": 1,
        "arithmetic_5da": 4,
        "nq_open": 4,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 4,
        "bbh_cot_fewshot_temporal_sequences": 1,
        "bbh_cot_fewshot_sports_understanding": 2,
        "bbh_cot_fewshot_snarks": 1
    },
    "brainly.in": {
        "count": 3074,
        "arc_challenge": 58,
        "arc_easy": 125,
        "headqa_en": 18,
        "gsm8k": 15,
        "mmlu_jurisprudence": 8,
        "mmlu_prehistory": 3,
        "mmlu_philosophy": 3,
        "mmlu_logical_fallacies": 3,
        "mmlu_international_law": 3,
        "mmlu_high_school_geography": 1,
        "mmlu_public_relations": 1,
        "mmlu_high_school_psychology": 3,
        "mmlu_high_school_microeconomics": 10,
        "mmlu_high_school_macroeconomics": 4,
        "mmlu_security_studies": 10,
        "mmlu_human_sexuality": 1,
        "mmlu_sociology": 11,
        "mmlu_econometrics": 7,
        "mmlu_miscellaneous": 14,
        "mmlu_marketing": 28,
        "mmlu_business_ethics": 1,
        "mmlu_virology": 3,
        "mmlu_professional_accounting": 4,
        "mmlu_medical_genetics": 5,
        "mmlu_global_facts": 1,
        "mmlu_college_medicine": 6,
        "mmlu_management": 27,
        "mmlu_nutrition": 4,
        "mmlu_clinical_knowledge": 9,
        "mmlu_high_school_statistics": 5,
        "mmlu_abstract_algebra": 8,
        "mmlu_college_biology": 6,
        "mmlu_high_school_mathematics": 11,
        "mmlu_computer_security": 5,
        "mmlu_high_school_biology": 5,
        "mmlu_anatomy": 10,
        "mmlu_high_school_chemistry": 9,
        "mmlu_machine_learning": 16,
        "mmlu_electrical_engineering": 34,
        "mmlu_elementary_mathematics": 81,
        "mmlu_college_mathematics": 2,
        "mmlu_college_physics": 18,
        "mmlu_college_computer_science": 7,
        "mmlu_conceptual_physics": 19,
        "mmlu_high_school_physics": 11,
        "mmlu_college_chemistry": 8,
        "mmlu_high_school_computer_science": 3,
        "mmlu_astronomy": 4,
        "gpqa_main_cot_n_shot": 2,
        "gpqa_extended_cot_n_shot": 2,
        "gpqa_extended_n_shot": 2,
        "gpqa_main_n_shot": 2,
        "gpqa_extended_generative_n_shot": 2,
        "gpqa_main_generative_n_shot": 2,
        "gpqa_extended_zeroshot": 2,
        "gpqa_main_zeroshot": 1,
        "gpqa_extended_cot_zeroshot": 2,
        "gpqa_main_cot_zeroshot": 2,
        "sciq": 35,
        "agieval_sat_math": 4,
        "agieval_math": 39,
        "agieval_lsat_ar": 6,
        "agieval_gaokao_english": 2,
        "agieval_aqua_rat": 11,
        "commonsense_qa": 5,
        "arithmetic_3da": 438,
        "arithmetic_3ds": 131,
        "arithmetic_4da": 45,
        "arithmetic_2ds": 311,
        "arithmetic_5ds": 1,
        "arithmetic_5da": 20,
        "arithmetic_1dc": 652,
        "arithmetic_4ds": 29,
        "arithmetic_2dm": 267,
        "arithmetic_2da": 330,
        "nq_open": 28,
        "triviaqa": 53
    },
    "www.gauthmath.com": {
        "count": 2965,
        "arc_challenge": 426,
        "arc_easy": 539,
        "gsm8k": 50,
        "mmlu_jurisprudence": 4,
        "mmlu_moral_disputes": 13,
        "mmlu_prehistory": 6,
        "mmlu_high_school_world_history": 39,
        "mmlu_professional_law": 5,
        "mmlu_philosophy": 32,
        "mmlu_high_school_us_history": 36,
        "mmlu_logical_fallacies": 4,
        "mmlu_formal_logic": 6,
        "mmlu_high_school_european_history": 39,
        "mmlu_high_school_geography": 12,
        "mmlu_public_relations": 4,
        "mmlu_high_school_psychology": 75,
        "mmlu_professional_psychology": 35,
        "mmlu_high_school_microeconomics": 43,
        "mmlu_high_school_government_and_politics": 10,
        "mmlu_high_school_macroeconomics": 42,
        "mmlu_human_sexuality": 2,
        "mmlu_sociology": 5,
        "mmlu_econometrics": 11,
        "mmlu_human_aging": 4,
        "mmlu_miscellaneous": 12,
        "mmlu_marketing": 25,
        "mmlu_business_ethics": 2,
        "mmlu_virology": 6,
        "mmlu_professional_accounting": 15,
        "mmlu_medical_genetics": 4,
        "mmlu_management": 10,
        "mmlu_nutrition": 2,
        "mmlu_clinical_knowledge": 7,
        "mmlu_professional_medicine": 28,
        "mmlu_high_school_statistics": 107,
        "mmlu_abstract_algebra": 8,
        "mmlu_college_biology": 3,
        "mmlu_high_school_mathematics": 84,
        "mmlu_computer_security": 3,
        "mmlu_high_school_biology": 22,
        "mmlu_anatomy": 3,
        "mmlu_high_school_chemistry": 26,
        "mmlu_machine_learning": 2,
        "mmlu_electrical_engineering": 7,
        "mmlu_elementary_mathematics": 414,
        "mmlu_college_mathematics": 7,
        "mmlu_college_physics": 29,
        "mmlu_college_computer_science": 4,
        "mmlu_conceptual_physics": 67,
        "mmlu_high_school_physics": 23,
        "mmlu_college_chemistry": 18,
        "mmlu_high_school_computer_science": 83,
        "mmlu_astronomy": 7,
        "sciq": 9,
        "agieval_sat_math": 112,
        "agieval_sat_en": 2,
        "agieval_sat_en_without_passage": 41,
        "agieval_math": 106,
        "agieval_lsat_lr": 1,
        "agieval_aqua_rat": 6,
        "commonsense_qa": 2,
        "arithmetic_3da": 22,
        "arithmetic_3ds": 69,
        "arithmetic_4da": 4,
        "arithmetic_2ds": 15,
        "arithmetic_5ds": 1,
        "arithmetic_5da": 1,
        "arithmetic_1dc": 6,
        "arithmetic_4ds": 11,
        "arithmetic_2dm": 69,
        "arithmetic_2da": 1,
        "nq_open": 13,
        "triviaqa": 4
    },
    "www.crackap.com": {
        "count": 2679,
        "mmlu_high_school_world_history": 138,
        "mmlu_high_school_us_history": 72,
        "mmlu_high_school_european_history": 97,
        "mmlu_high_school_geography": 151,
        "mmlu_high_school_psychology": 661,
        "mmlu_high_school_microeconomics": 225,
        "mmlu_high_school_government_and_politics": 58,
        "mmlu_high_school_macroeconomics": 177,
        "mmlu_high_school_statistics": 425,
        "mmlu_high_school_mathematics": 39,
        "mmlu_high_school_biology": 137,
        "mmlu_high_school_chemistry": 231,
        "mmlu_high_school_physics": 268
    },
    "arxiv.org": {
        "count": 2631,
        "arc_challenge": 8,
        "arc_easy": 7,
        "gsm8k": 498,
        "mmlu_moral_scenarios": 32,
        "mmlu_prehistory": 1,
        "mmlu_professional_law": 6,
        "mmlu_high_school_us_history": 4,
        "mmlu_formal_logic": 3,
        "mmlu_professional_psychology": 2,
        "mmlu_human_aging": 1,
        "mmlu_professional_accounting": 3,
        "mmlu_professional_medicine": 1,
        "mmlu_high_school_mathematics": 9,
        "mmlu_high_school_chemistry": 2,
        "mmlu_machine_learning": 1,
        "mmlu_elementary_mathematics": 1,
        "mmlu_high_school_physics": 2,
        "mmlu_college_chemistry": 1,
        "gpqa_diamond_cot_n_shot": 7,
        "gpqa_main_cot_n_shot": 23,
        "gpqa_extended_cot_n_shot": 25,
        "gpqa_extended_n_shot": 25,
        "gpqa_main_n_shot": 18,
        "gpqa_diamond_n_shot": 7,
        "gpqa_extended_generative_n_shot": 25,
        "gpqa_diamond_generative_n_shot": 7,
        "gpqa_main_generative_n_shot": 18,
        "gpqa_extended_zeroshot": 25,
        "gpqa_main_zeroshot": 15,
        "gpqa_diamond_zeroshot": 5,
        "gpqa_diamond_cot_zeroshot": 5,
        "gpqa_extended_cot_zeroshot": 25,
        "gpqa_main_cot_zeroshot": 18,
        "agieval_math": 29,
        "agieval_lsat_lr": 2,
        "agieval_logiqa_en": 15,
        "agieval_aqua_rat": 48,
        "qasper_bool": 388,
        "toxigen": 2,
        "arithmetic_3da": 8,
        "arithmetic_3ds": 3,
        "arithmetic_4da": 2,
        "arithmetic_5ds": 4,
        "arithmetic_5da": 3,
        "arithmetic_4ds": 96,
        "triviaqa": 71,
        "bbh_cot_fewshot_word_sorting": 16,
        "bbh_cot_fewshot_web_of_lies": 87,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 469,
        "bbh_cot_fewshot_tracking_shuffled_objects_seven_objects": 184,
        "bbh_cot_fewshot_tracking_shuffled_objects_five_objects": 271,
        "bbh_cot_fewshot_temporal_sequences": 4,
        "bbh_cot_fewshot_sports_understanding": 94,
        "bbh_cot_fewshot_snarks": 5
    },
    "www.researchgate.net": {
        "count": 2055,
        "gsm8k": 77,
        "arc_challenge_mt_pl": 9,
        "mmlu_jurisprudence": 2,
        "mmlu_moral_disputes": 6,
        "mmlu_moral_scenarios": 22,
        "mmlu_prehistory": 17,
        "mmlu_professional_law": 3,
        "mmlu_philosophy": 1,
        "mmlu_formal_logic": 2,
        "mmlu_high_school_european_history": 1,
        "mmlu_high_school_geography": 3,
        "mmlu_public_relations": 4,
        "mmlu_high_school_psychology": 11,
        "mmlu_professional_psychology": 35,
        "mmlu_high_school_microeconomics": 2,
        "mmlu_security_studies": 10,
        "mmlu_human_sexuality": 2,
        "mmlu_sociology": 7,
        "mmlu_us_foreign_policy": 1,
        "mmlu_econometrics": 8,
        "mmlu_human_aging": 3,
        "mmlu_miscellaneous": 2,
        "mmlu_marketing": 24,
        "mmlu_business_ethics": 7,
        "mmlu_virology": 1,
        "mmlu_professional_accounting": 1,
        "mmlu_global_facts": 1,
        "mmlu_college_medicine": 1,
        "mmlu_management": 3,
        "mmlu_nutrition": 2,
        "mmlu_clinical_knowledge": 2,
        "mmlu_professional_medicine": 8,
        "mmlu_high_school_statistics": 8,
        "mmlu_college_biology": 6,
        "mmlu_high_school_mathematics": 5,
        "mmlu_computer_security": 1,
        "mmlu_high_school_biology": 3,
        "mmlu_high_school_chemistry": 2,
        "mmlu_machine_learning": 4,
        "mmlu_elementary_mathematics": 1,
        "mmlu_college_computer_science": 1,
        "mmlu_conceptual_physics": 1,
        "mmlu_college_chemistry": 3,
        "mmlu_high_school_computer_science": 2,
        "gpqa_diamond_cot_n_shot": 15,
        "gpqa_main_cot_n_shot": 31,
        "gpqa_extended_cot_n_shot": 40,
        "gpqa_extended_n_shot": 40,
        "gpqa_main_n_shot": 29,
        "gpqa_diamond_n_shot": 15,
        "gpqa_extended_generative_n_shot": 40,
        "gpqa_diamond_generative_n_shot": 15,
        "gpqa_main_generative_n_shot": 30,
        "gpqa_extended_zeroshot": 41,
        "gpqa_main_zeroshot": 27,
        "gpqa_diamond_zeroshot": 15,
        "gpqa_diamond_cot_zeroshot": 15,
        "gpqa_extended_cot_zeroshot": 41,
        "gpqa_main_cot_zeroshot": 31,
        "sciq": 5,
        "agieval_sat_math": 2,
        "agieval_sat_en_without_passage": 4,
        "agieval_math": 5,
        "agieval_lsat_lr": 10,
        "agieval_lsat_ar": 27,
        "agieval_logiqa_en": 79,
        "agieval_gaokao_english": 8,
        "agieval_aqua_rat": 13,
        "qasper_bool": 98,
        "commonsense_qa": 1,
        "toxigen": 6,
        "arithmetic_5ds": 3,
        "arithmetic_5da": 7,
        "arithmetic_4ds": 1,
        "nq_open": 2,
        "triviaqa": 30,
        "bbh_cot_fewshot_word_sorting": 6,
        "bbh_cot_fewshot_web_of_lies": 34,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 324,
        "bbh_cot_fewshot_tracking_shuffled_objects_seven_objects": 319,
        "bbh_cot_fewshot_tracking_shuffled_objects_five_objects": 290,
        "bbh_cot_fewshot_temporal_sequences": 9,
        "bbh_cot_fewshot_sports_understanding": 27,
        "groundcocoa": 1,
        "polemo2_in": 4
    },
    "www.toppr.com": {
        "count": 1913,
        "arc_challenge": 58,
        "arc_easy": 110,
        "headqa_en": 76,
        "gsm8k": 13,
        "mmlu_jurisprudence": 7,
        "mmlu_moral_disputes": 1,
        "mmlu_prehistory": 8,
        "mmlu_professional_law": 3,
        "mmlu_logical_fallacies": 1,
        "mmlu_international_law": 9,
        "mmlu_high_school_geography": 5,
        "mmlu_high_school_psychology": 1,
        "mmlu_professional_psychology": 1,
        "mmlu_high_school_microeconomics": 33,
        "mmlu_high_school_government_and_politics": 1,
        "mmlu_high_school_macroeconomics": 10,
        "mmlu_security_studies": 2,
        "mmlu_sociology": 79,
        "mmlu_human_aging": 2,
        "mmlu_miscellaneous": 22,
        "mmlu_marketing": 8,
        "mmlu_business_ethics": 2,
        "mmlu_professional_accounting": 1,
        "mmlu_medical_genetics": 5,
        "mmlu_college_medicine": 18,
        "mmlu_nutrition": 24,
        "mmlu_clinical_knowledge": 18,
        "mmlu_high_school_statistics": 6,
        "mmlu_abstract_algebra": 2,
        "mmlu_college_biology": 54,
        "mmlu_high_school_mathematics": 11,
        "mmlu_high_school_biology": 66,
        "mmlu_anatomy": 8,
        "mmlu_high_school_chemistry": 45,
        "mmlu_machine_learning": 4,
        "mmlu_electrical_engineering": 23,
        "mmlu_elementary_mathematics": 7,
        "mmlu_college_mathematics": 7,
        "mmlu_college_physics": 70,
        "mmlu_college_computer_science": 2,
        "mmlu_conceptual_physics": 58,
        "mmlu_high_school_physics": 64,
        "mmlu_college_chemistry": 28,
        "mmlu_astronomy": 5,
        "gpqa_diamond_cot_n_shot": 17,
        "gpqa_main_cot_n_shot": 27,
        "gpqa_extended_cot_n_shot": 29,
        "gpqa_extended_n_shot": 29,
        "gpqa_main_n_shot": 25,
        "gpqa_diamond_n_shot": 16,
        "gpqa_extended_generative_n_shot": 29,
        "gpqa_diamond_generative_n_shot": 16,
        "gpqa_main_generative_n_shot": 25,
        "gpqa_extended_zeroshot": 29,
        "gpqa_main_zeroshot": 23,
        "gpqa_diamond_zeroshot": 16,
        "gpqa_diamond_cot_zeroshot": 16,
        "gpqa_extended_cot_zeroshot": 29,
        "gpqa_main_cot_zeroshot": 25,
        "sciq": 58,
        "agieval_sat_math": 33,
        "agieval_sat_en_without_passage": 7,
        "agieval_math": 156,
        "agieval_aqua_rat": 34,
        "commonsense_qa": 2,
        "toxigen": 1,
        "arithmetic_3da": 7,
        "arithmetic_3ds": 58,
        "arithmetic_4da": 2,
        "arithmetic_2ds": 6,
        "arithmetic_1dc": 7,
        "arithmetic_2dm": 25,
        "arithmetic_2da": 4,
        "nq_open": 33,
        "triviaqa": 151
    },
    "homework.study.com": {
        "count": 1526,
        "arc_challenge": 43,
        "arc_easy": 55,
        "headqa_en": 20,
        "webqs": 1,
        "gsm8k": 9,
        "mmlu_professional_law": 2,
        "mmlu_high_school_geography": 3,
        "mmlu_high_school_psychology": 17,
        "mmlu_professional_psychology": 7,
        "mmlu_high_school_microeconomics": 234,
        "mmlu_high_school_macroeconomics": 281,
        "mmlu_security_studies": 2,
        "mmlu_sociology": 3,
        "mmlu_us_foreign_policy": 1,
        "mmlu_econometrics": 7,
        "mmlu_human_aging": 2,
        "mmlu_miscellaneous": 28,
        "mmlu_marketing": 4,
        "mmlu_virology": 3,
        "mmlu_professional_accounting": 20,
        "mmlu_medical_genetics": 2,
        "mmlu_college_medicine": 5,
        "mmlu_management": 6,
        "mmlu_nutrition": 11,
        "mmlu_clinical_knowledge": 15,
        "mmlu_professional_medicine": 8,
        "mmlu_high_school_statistics": 104,
        "mmlu_abstract_algebra": 3,
        "mmlu_college_biology": 17,
        "mmlu_high_school_mathematics": 16,
        "mmlu_high_school_biology": 71,
        "mmlu_anatomy": 27,
        "mmlu_high_school_chemistry": 32,
        "mmlu_electrical_engineering": 3,
        "mmlu_elementary_mathematics": 14,
        "mmlu_college_mathematics": 1,
        "mmlu_college_physics": 33,
        "mmlu_college_computer_science": 1,
        "mmlu_conceptual_physics": 190,
        "mmlu_high_school_physics": 42,
        "mmlu_college_chemistry": 12,
        "mmlu_high_school_computer_science": 2,
        "mmlu_astronomy": 7,
        "gpqa_diamond_cot_n_shot": 5,
        "gpqa_main_cot_n_shot": 5,
        "gpqa_extended_cot_n_shot": 5,
        "gpqa_extended_n_shot": 5,
        "gpqa_main_n_shot": 5,
        "gpqa_diamond_n_shot": 5,
        "gpqa_extended_generative_n_shot": 5,
        "gpqa_diamond_generative_n_shot": 5,
        "gpqa_main_generative_n_shot": 5,
        "gpqa_extended_zeroshot": 5,
        "gpqa_main_zeroshot": 4,
        "gpqa_diamond_zeroshot": 5,
        "gpqa_diamond_cot_zeroshot": 5,
        "gpqa_extended_cot_zeroshot": 5,
        "gpqa_main_cot_zeroshot": 5,
        "sciq": 24,
        "agieval_sat_math": 2,
        "agieval_math": 18,
        "arithmetic_3da": 2,
        "arithmetic_3ds": 2,
        "arithmetic_2ds": 2,
        "arithmetic_1dc": 15,
        "arithmetic_2dm": 2,
        "arithmetic_2da": 7,
        "nq_open": 5,
        "triviaqa": 9
    },
    "nlp.stanford.edu": {
        "count": 1520,
        "gsm8k": 110,
        "mmlu_jurisprudence": 12,
        "mmlu_moral_disputes": 6,
        "mmlu_moral_scenarios": 118,
        "mmlu_prehistory": 12,
        "mmlu_high_school_world_history": 121,
        "mmlu_professional_law": 24,
        "mmlu_philosophy": 15,
        "mmlu_high_school_us_history": 158,
        "mmlu_logical_fallacies": 29,
        "mmlu_formal_logic": 66,
        "mmlu_high_school_european_history": 87,
        "mmlu_international_law": 4,
        "mmlu_world_religions": 6,
        "mmlu_high_school_geography": 11,
        "mmlu_public_relations": 17,
        "mmlu_high_school_psychology": 9,
        "mmlu_professional_psychology": 30,
        "mmlu_high_school_microeconomics": 2,
        "mmlu_high_school_government_and_politics": 4,
        "mmlu_high_school_macroeconomics": 3,
        "mmlu_security_studies": 4,
        "mmlu_human_sexuality": 24,
        "mmlu_sociology": 3,
        "mmlu_us_foreign_policy": 1,
        "mmlu_econometrics": 72,
        "mmlu_human_aging": 14,
        "mmlu_miscellaneous": 13,
        "mmlu_marketing": 20,
        "mmlu_business_ethics": 43,
        "mmlu_virology": 1,
        "mmlu_professional_accounting": 8,
        "mmlu_medical_genetics": 12,
        "mmlu_global_facts": 3,
        "mmlu_college_medicine": 24,
        "mmlu_nutrition": 4,
        "mmlu_clinical_knowledge": 1,
        "mmlu_professional_medicine": 30,
        "mmlu_high_school_statistics": 6,
        "mmlu_abstract_algebra": 16,
        "mmlu_college_biology": 27,
        "mmlu_high_school_mathematics": 6,
        "mmlu_computer_security": 26,
        "mmlu_high_school_biology": 1,
        "mmlu_high_school_chemistry": 8,
        "mmlu_machine_learning": 32,
        "mmlu_electrical_engineering": 1,
        "mmlu_elementary_mathematics": 32,
        "mmlu_college_mathematics": 7,
        "mmlu_college_physics": 8,
        "mmlu_college_computer_science": 35,
        "mmlu_conceptual_physics": 12,
        "mmlu_high_school_physics": 16,
        "mmlu_college_chemistry": 79,
        "mmlu_high_school_computer_science": 4,
        "mmlu_astronomy": 3,
        "agieval_math": 80
    },
    "testbook.com": {
        "count": 1519,
        "arc_challenge": 25,
        "arc_easy": 55,
        "headqa_en": 33,
        "gsm8k": 24,
        "mmlu_jurisprudence": 1,
        "mmlu_moral_disputes": 1,
        "mmlu_prehistory": 7,
        "mmlu_professional_law": 1,
        "mmlu_philosophy": 1,
        "mmlu_logical_fallacies": 2,
        "mmlu_international_law": 10,
        "mmlu_world_religions": 3,
        "mmlu_high_school_geography": 24,
        "mmlu_public_relations": 3,
        "mmlu_high_school_psychology": 12,
        "mmlu_professional_psychology": 11,
        "mmlu_high_school_microeconomics": 32,
        "mmlu_high_school_government_and_politics": 3,
        "mmlu_high_school_macroeconomics": 14,
        "mmlu_security_studies": 12,
        "mmlu_human_sexuality": 1,
        "mmlu_sociology": 8,
        "mmlu_econometrics": 10,
        "mmlu_human_aging": 1,
        "mmlu_miscellaneous": 25,
        "mmlu_marketing": 16,
        "mmlu_business_ethics": 8,
        "mmlu_professional_accounting": 4,
        "mmlu_medical_genetics": 1,
        "mmlu_global_facts": 2,
        "mmlu_college_medicine": 8,
        "mmlu_management": 5,
        "mmlu_nutrition": 35,
        "mmlu_clinical_knowledge": 12,
        "mmlu_high_school_statistics": 12,
        "mmlu_abstract_algebra": 4,
        "mmlu_college_biology": 10,
        "mmlu_high_school_mathematics": 12,
        "mmlu_computer_security": 7,
        "mmlu_high_school_biology": 17,
        "mmlu_anatomy": 1,
        "mmlu_high_school_chemistry": 26,
        "mmlu_machine_learning": 5,
        "mmlu_electrical_engineering": 121,
        "mmlu_elementary_mathematics": 7,
        "mmlu_college_mathematics": 9,
        "mmlu_college_physics": 24,
        "mmlu_college_computer_science": 41,
        "mmlu_conceptual_physics": 26,
        "mmlu_high_school_physics": 15,
        "mmlu_college_chemistry": 13,
        "mmlu_high_school_computer_science": 1,
        "mmlu_astronomy": 7,
        "gpqa_extended_cot_n_shot": 5,
        "gpqa_extended_n_shot": 4,
        "gpqa_extended_generative_n_shot": 4,
        "gpqa_main_generative_n_shot": 1,
        "gpqa_extended_zeroshot": 5,
        "gpqa_extended_cot_zeroshot": 4,
        "sciq": 15,
        "agieval_sat_math": 20,
        "agieval_math": 67,
        "agieval_aqua_rat": 50,
        "commonsense_qa": 2,
        "arithmetic_3ds": 13,
        "arithmetic_2ds": 5,
        "arithmetic_5ds": 1,
        "arithmetic_5da": 13,
        "arithmetic_1dc": 27,
        "arithmetic_4ds": 34,
        "arithmetic_2dm": 369,
        "nq_open": 46,
        "triviaqa": 66
    },
    "www.brainscape.com": {
        "count": 1509,
        "mmlu_professional_law": 1217,
        "mmlu_professional_psychology": 131,
        "mmlu_professional_accounting": 156,
        "arithmetic_3da": 1,
        "triviaqa": 4
    },
    "openreview.net": {
        "count": 1378,
        "arc_challenge": 16,
        "arc_easy": 2,
        "gsm8k": 399,
        "mmlu_moral_disputes": 1,
        "mmlu_high_school_mathematics": 6,
        "mmlu_machine_learning": 1,
        "mmlu_elementary_mathematics": 2,
        "mmlu_high_school_physics": 2,
        "gpqa_diamond_cot_n_shot": 6,
        "gpqa_main_cot_n_shot": 8,
        "gpqa_extended_cot_n_shot": 11,
        "gpqa_extended_n_shot": 11,
        "gpqa_main_n_shot": 8,
        "gpqa_diamond_n_shot": 6,
        "gpqa_extended_generative_n_shot": 11,
        "gpqa_diamond_generative_n_shot": 6,
        "gpqa_main_generative_n_shot": 7,
        "gpqa_extended_zeroshot": 10,
        "gpqa_main_zeroshot": 7,
        "gpqa_diamond_zeroshot": 5,
        "gpqa_diamond_cot_zeroshot": 5,
        "gpqa_extended_cot_zeroshot": 10,
        "gpqa_main_cot_zeroshot": 7,
        "agieval_math": 6,
        "agieval_lsat_lr": 4,
        "agieval_lsat_ar": 14,
        "agieval_logiqa_en": 12,
        "agieval_aqua_rat": 25,
        "qasper_bool": 14,
        "triviaqa": 27,
        "bbh_cot_fewshot_word_sorting": 6,
        "bbh_cot_fewshot_web_of_lies": 71,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 349,
        "bbh_cot_fewshot_tracking_shuffled_objects_seven_objects": 97,
        "bbh_cot_fewshot_tracking_shuffled_objects_five_objects": 166,
        "bbh_cot_fewshot_temporal_sequences": 8,
        "bbh_cot_fewshot_sports_understanding": 28,
        "bbh_cot_fewshot_snarks": 4
    },
    "www.numerade.com": {
        "count": 1120,
        "arc_challenge": 56,
        "arc_easy": 67,
        "mmlu_jurisprudence": 1,
        "mmlu_prehistory": 1,
        "mmlu_professional_law": 8,
        "mmlu_philosophy": 4,
        "mmlu_logical_fallacies": 1,
        "mmlu_formal_logic": 6,
        "mmlu_high_school_psychology": 142,
        "mmlu_professional_psychology": 4,
        "mmlu_high_school_microeconomics": 30,
        "mmlu_high_school_government_and_politics": 8,
        "mmlu_high_school_macroeconomics": 15,
        "mmlu_security_studies": 2,
        "mmlu_sociology": 3,
        "mmlu_econometrics": 28,
        "mmlu_miscellaneous": 4,
        "mmlu_marketing": 2,
        "mmlu_virology": 3,
        "mmlu_professional_accounting": 21,
        "mmlu_medical_genetics": 1,
        "mmlu_college_medicine": 1,
        "mmlu_management": 2,
        "mmlu_nutrition": 2,
        "mmlu_high_school_statistics": 168,
        "mmlu_abstract_algebra": 11,
        "mmlu_college_biology": 3,
        "mmlu_high_school_mathematics": 21,
        "mmlu_high_school_biology": 33,
        "mmlu_anatomy": 1,
        "mmlu_high_school_chemistry": 55,
        "mmlu_machine_learning": 1,
        "mmlu_electrical_engineering": 2,
        "mmlu_elementary_mathematics": 125,
        "mmlu_college_mathematics": 5,
        "mmlu_college_physics": 46,
        "mmlu_college_computer_science": 12,
        "mmlu_conceptual_physics": 22,
        "mmlu_high_school_physics": 25,
        "mmlu_college_chemistry": 21,
        "mmlu_high_school_computer_science": 6,
        "gpqa_diamond_cot_n_shot": 2,
        "gpqa_main_cot_n_shot": 5,
        "gpqa_extended_cot_n_shot": 5,
        "gpqa_extended_n_shot": 5,
        "gpqa_main_n_shot": 5,
        "gpqa_diamond_n_shot": 2,
        "gpqa_extended_generative_n_shot": 5,
        "gpqa_diamond_generative_n_shot": 2,
        "gpqa_main_generative_n_shot": 5,
        "gpqa_extended_zeroshot": 5,
        "gpqa_main_zeroshot": 5,
        "gpqa_diamond_zeroshot": 2,
        "gpqa_diamond_cot_zeroshot": 2,
        "gpqa_extended_cot_zeroshot": 5,
        "gpqa_main_cot_zeroshot": 5,
        "agieval_sat_math": 18,
        "agieval_sat_en_without_passage": 2,
        "agieval_math": 22,
        "arithmetic_3da": 1,
        "arithmetic_3ds": 3,
        "arithmetic_2ds": 2,
        "arithmetic_5ds": 1,
        "arithmetic_2dm": 3,
        "nq_open": 3,
        "triviaqa": 36
    },
    "aclanthology.org": {
        "count": 1079,
        "gsm8k": 171,
        "mmlu_moral_scenarios": 8,
        "mmlu_formal_logic": 2,
        "mmlu_professional_accounting": 1,
        "mmlu_college_medicine": 1,
        "mmlu_clinical_knowledge": 1,
        "mmlu_professional_medicine": 2,
        "mmlu_abstract_algebra": 1,
        "mmlu_high_school_mathematics": 2,
        "agieval_math": 2,
        "agieval_logiqa_en": 2,
        "agieval_aqua_rat": 14,
        "qasper_bool": 272,
        "toxigen": 1,
        "triviaqa": 24,
        "bbh_cot_fewshot_word_sorting": 4,
        "bbh_cot_fewshot_web_of_lies": 65,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 387,
        "bbh_cot_fewshot_tracking_shuffled_objects_five_objects": 78,
        "bbh_cot_fewshot_temporal_sequences": 23,
        "bbh_cot_fewshot_sports_understanding": 16,
        "bbh_cot_fewshot_snarks": 2
    },
    "global.oup.com": {
        "count": 952,
        "mmlu_moral_disputes": 84,
        "mmlu_prehistory": 160,
        "mmlu_philosophy": 261,
        "mmlu_virology": 62,
        "mmlu_management": 77,
        "mmlu_nutrition": 153,
        "mmlu_clinical_knowledge": 72,
        "mmlu_anatomy": 52,
        "mmlu_college_chemistry": 31
    },
    "www.scribd.com": {
        "count": 945,
        "arc_challenge": 19,
        "arc_easy": 27,
        "headqa_en": 6,
        "gsm8k": 42,
        "arc_challenge_mt_pl": 9,
        "mmlu_jurisprudence": 4,
        "mmlu_moral_disputes": 1,
        "mmlu_moral_scenarios": 35,
        "mmlu_prehistory": 1,
        "mmlu_high_school_world_history": 11,
        "mmlu_professional_law": 28,
        "mmlu_philosophy": 30,
        "mmlu_logical_fallacies": 4,
        "mmlu_formal_logic": 1,
        "mmlu_high_school_european_history": 2,
        "mmlu_high_school_geography": 1,
        "mmlu_public_relations": 27,
        "mmlu_high_school_psychology": 26,
        "mmlu_professional_psychology": 5,
        "mmlu_high_school_microeconomics": 4,
        "mmlu_high_school_macroeconomics": 3,
        "mmlu_security_studies": 5,
        "mmlu_human_sexuality": 1,
        "mmlu_econometrics": 8,
        "mmlu_human_aging": 2,
        "mmlu_miscellaneous": 8,
        "mmlu_marketing": 47,
        "mmlu_business_ethics": 6,
        "mmlu_virology": 1,
        "mmlu_professional_accounting": 57,
        "mmlu_global_facts": 1,
        "mmlu_college_medicine": 1,
        "mmlu_management": 6,
        "mmlu_nutrition": 5,
        "mmlu_clinical_knowledge": 1,
        "mmlu_professional_medicine": 20,
        "mmlu_high_school_statistics": 38,
        "mmlu_college_biology": 3,
        "mmlu_high_school_mathematics": 5,
        "mmlu_computer_security": 14,
        "mmlu_high_school_biology": 4,
        "mmlu_anatomy": 1,
        "mmlu_high_school_chemistry": 9,
        "mmlu_machine_learning": 7,
        "mmlu_electrical_engineering": 10,
        "mmlu_elementary_mathematics": 50,
        "mmlu_college_mathematics": 2,
        "mmlu_college_physics": 10,
        "mmlu_college_computer_science": 4,
        "mmlu_conceptual_physics": 13,
        "mmlu_high_school_physics": 5,
        "mmlu_college_chemistry": 4,
        "mmlu_high_school_computer_science": 5,
        "mmlu_astronomy": 1,
        "gpqa_main_cot_n_shot": 4,
        "gpqa_extended_cot_n_shot": 5,
        "gpqa_extended_n_shot": 4,
        "gpqa_main_n_shot": 3,
        "gpqa_extended_generative_n_shot": 4,
        "gpqa_main_generative_n_shot": 3,
        "gpqa_extended_zeroshot": 4,
        "gpqa_main_zeroshot": 3,
        "gpqa_extended_cot_zeroshot": 4,
        "gpqa_main_cot_zeroshot": 3,
        "sciq": 2,
        "agieval_sat_math": 17,
        "agieval_sat_en_without_passage": 51,
        "agieval_math": 12,
        "agieval_lsat_lr": 7,
        "agieval_logiqa_en": 3,
        "agieval_gaokao_english": 14,
        "agieval_aqua_rat": 71,
        "toxigen": 1,
        "arithmetic_3da": 3,
        "arithmetic_3ds": 1,
        "arithmetic_5ds": 3,
        "arithmetic_5da": 1,
        "arithmetic_4ds": 7,
        "triviaqa": 29,
        "bbh_cot_fewshot_word_sorting": 6,
        "bbh_cot_fewshot_web_of_lies": 1,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 2,
        "bbh_cot_fewshot_tracking_shuffled_objects_seven_objects": 10,
        "bbh_cot_fewshot_tracking_shuffled_objects_five_objects": 5,
        "bbh_cot_fewshot_temporal_sequences": 11,
        "bbh_cot_fewshot_sports_understanding": 2,
        "groundcocoa": 1,
        "polemo2_in": 8
    },
    "www.quizwise.com": {
        "count": 927,
        "triviaqa": 927
    },
    "www.doubtnut.com": {
        "count": 923,
        "arc_easy": 6,
        "headqa_en": 42,
        "gsm8k": 8,
        "mmlu_moral_disputes": 1,
        "mmlu_prehistory": 3,
        "mmlu_international_law": 7,
        "mmlu_high_school_psychology": 2,
        "mmlu_professional_psychology": 1,
        "mmlu_high_school_microeconomics": 15,
        "mmlu_high_school_macroeconomics": 4,
        "mmlu_security_studies": 6,
        "mmlu_miscellaneous": 2,
        "mmlu_marketing": 10,
        "mmlu_business_ethics": 4,
        "mmlu_professional_accounting": 8,
        "mmlu_medical_genetics": 2,
        "mmlu_college_medicine": 13,
        "mmlu_management": 1,
        "mmlu_nutrition": 34,
        "mmlu_clinical_knowledge": 16,
        "mmlu_high_school_statistics": 7,
        "mmlu_abstract_algebra": 9,
        "mmlu_college_biology": 22,
        "mmlu_high_school_mathematics": 12,
        "mmlu_high_school_biology": 34,
        "mmlu_anatomy": 1,
        "mmlu_high_school_chemistry": 44,
        "mmlu_machine_learning": 4,
        "mmlu_electrical_engineering": 12,
        "mmlu_elementary_mathematics": 10,
        "mmlu_college_mathematics": 5,
        "mmlu_college_physics": 28,
        "mmlu_conceptual_physics": 23,
        "mmlu_high_school_physics": 50,
        "mmlu_college_chemistry": 29,
        "mmlu_astronomy": 5,
        "gpqa_diamond_cot_n_shot": 4,
        "gpqa_main_cot_n_shot": 11,
        "gpqa_extended_cot_n_shot": 12,
        "gpqa_extended_n_shot": 12,
        "gpqa_main_n_shot": 10,
        "gpqa_diamond_n_shot": 4,
        "gpqa_extended_generative_n_shot": 12,
        "gpqa_diamond_generative_n_shot": 4,
        "gpqa_main_generative_n_shot": 11,
        "gpqa_extended_zeroshot": 13,
        "gpqa_main_zeroshot": 9,
        "gpqa_diamond_zeroshot": 4,
        "gpqa_diamond_cot_zeroshot": 4,
        "gpqa_extended_cot_zeroshot": 13,
        "gpqa_main_cot_zeroshot": 11,
        "sciq": 18,
        "agieval_sat_math": 80,
        "agieval_sat_en": 16,
        "agieval_sat_en_without_passage": 10,
        "agieval_math": 67,
        "agieval_aqua_rat": 18,
        "arithmetic_3ds": 13,
        "arithmetic_4da": 1,
        "arithmetic_2ds": 5,
        "arithmetic_5ds": 2,
        "arithmetic_1dc": 8,
        "arithmetic_4ds": 3,
        "arithmetic_2dm": 21,
        "nq_open": 22,
        "triviaqa": 25
    },
    "www.facebook.com": {
        "count": 919,
        "mmlu_professional_medicine": 22,
        "mmlu_anatomy": 11,
        "agieval_aqua_rat": 3,
        "commonsense_qa": 29,
        "toxigen": 22,
        "arithmetic_3da": 3,
        "arithmetic_3ds": 2,
        "arithmetic_2ds": 4,
        "arithmetic_5ds": 1,
        "arithmetic_1dc": 5,
        "arithmetic_4ds": 2,
        "nq_open": 10,
        "triviaqa": 154,
        "bbh_cot_fewshot_web_of_lies": 23,
        "bbh_cot_fewshot_tracking_shuffled_objects_five_objects": 4,
        "bbh_cot_fewshot_temporal_sequences": 38,
        "bbh_cot_fewshot_sports_understanding": 1,
        "bbh_cot_fewshot_snarks": 5,
        "groundcocoa": 578,
        "polemo2_in": 2
    },
    "www.studocu.com": {
        "count": 815,
        "arc_challenge": 7,
        "arc_easy": 16,
        "headqa_en": 11,
        "gsm8k": 3,
        "arc_challenge_mt_pl": 15,
        "mmlu_jurisprudence": 14,
        "mmlu_moral_disputes": 1,
        "mmlu_high_school_world_history": 5,
        "mmlu_professional_law": 69,
        "mmlu_philosophy": 25,
        "mmlu_logical_fallacies": 7,
        "mmlu_formal_logic": 3,
        "mmlu_high_school_european_history": 3,
        "mmlu_international_law": 3,
        "mmlu_high_school_geography": 3,
        "mmlu_high_school_psychology": 17,
        "mmlu_professional_psychology": 5,
        "mmlu_high_school_microeconomics": 36,
        "mmlu_high_school_government_and_politics": 1,
        "mmlu_high_school_macroeconomics": 19,
        "mmlu_security_studies": 4,
        "mmlu_human_sexuality": 4,
        "mmlu_sociology": 4,
        "mmlu_us_foreign_policy": 3,
        "mmlu_econometrics": 43,
        "mmlu_human_aging": 7,
        "mmlu_miscellaneous": 9,
        "mmlu_marketing": 58,
        "mmlu_business_ethics": 25,
        "mmlu_virology": 14,
        "mmlu_professional_accounting": 60,
        "mmlu_global_facts": 3,
        "mmlu_management": 23,
        "mmlu_nutrition": 10,
        "mmlu_clinical_knowledge": 3,
        "mmlu_professional_medicine": 6,
        "mmlu_high_school_statistics": 20,
        "mmlu_abstract_algebra": 4,
        "mmlu_college_biology": 1,
        "mmlu_high_school_mathematics": 3,
        "mmlu_computer_security": 5,
        "mmlu_high_school_biology": 29,
        "mmlu_anatomy": 18,
        "mmlu_high_school_chemistry": 3,
        "mmlu_machine_learning": 18,
        "mmlu_electrical_engineering": 4,
        "mmlu_elementary_mathematics": 14,
        "mmlu_college_computer_science": 5,
        "mmlu_conceptual_physics": 9,
        "mmlu_high_school_physics": 8,
        "mmlu_high_school_computer_science": 7,
        "mmlu_astronomy": 8,
        "gpqa_main_cot_n_shot": 1,
        "gpqa_extended_cot_n_shot": 1,
        "gpqa_extended_n_shot": 1,
        "gpqa_main_n_shot": 1,
        "gpqa_extended_generative_n_shot": 1,
        "gpqa_main_generative_n_shot": 1,
        "gpqa_extended_zeroshot": 1,
        "gpqa_main_zeroshot": 1,
        "gpqa_extended_cot_zeroshot": 1,
        "gpqa_main_cot_zeroshot": 1,
        "sciq": 1,
        "agieval_sat_math": 2,
        "agieval_sat_en": 8,
        "agieval_sat_en_without_passage": 34,
        "agieval_lsat_lr": 6,
        "agieval_lsat_ar": 23,
        "arithmetic_3da": 4,
        "arithmetic_3ds": 11,
        "arithmetic_4da": 2,
        "arithmetic_2ds": 3,
        "arithmetic_1dc": 2,
        "arithmetic_4ds": 1,
        "arithmetic_2dm": 2,
        "nq_open": 5,
        "triviaqa": 4,
        "polemo2_out": 2
    },
    "askfilo.com": {
        "count": 779,
        "arc_challenge": 34,
        "arc_easy": 63,
        "headqa_en": 15,
        "mmlu_moral_disputes": 1,
        "mmlu_international_law": 1,
        "mmlu_high_school_geography": 1,
        "mmlu_high_school_psychology": 2,
        "mmlu_professional_psychology": 1,
        "mmlu_high_school_microeconomics": 7,
        "mmlu_high_school_macroeconomics": 10,
        "mmlu_sociology": 1,
        "mmlu_econometrics": 5,
        "mmlu_human_aging": 2,
        "mmlu_miscellaneous": 3,
        "mmlu_marketing": 2,
        "mmlu_professional_accounting": 2,
        "mmlu_medical_genetics": 7,
        "mmlu_college_medicine": 4,
        "mmlu_nutrition": 4,
        "mmlu_high_school_statistics": 5,
        "mmlu_college_biology": 18,
        "mmlu_high_school_mathematics": 6,
        "mmlu_computer_security": 2,
        "mmlu_high_school_biology": 27,
        "mmlu_anatomy": 13,
        "mmlu_high_school_chemistry": 2,
        "mmlu_machine_learning": 1,
        "mmlu_electrical_engineering": 9,
        "mmlu_elementary_mathematics": 18,
        "mmlu_college_mathematics": 1,
        "mmlu_college_physics": 10,
        "mmlu_conceptual_physics": 30,
        "mmlu_high_school_physics": 29,
        "mmlu_college_chemistry": 12,
        "mmlu_astronomy": 7,
        "gpqa_diamond_cot_n_shot": 2,
        "gpqa_main_cot_n_shot": 5,
        "gpqa_extended_cot_n_shot": 3,
        "gpqa_extended_n_shot": 3,
        "gpqa_main_n_shot": 4,
        "gpqa_diamond_n_shot": 2,
        "gpqa_extended_generative_n_shot": 4,
        "gpqa_diamond_generative_n_shot": 2,
        "gpqa_main_generative_n_shot": 4,
        "gpqa_extended_zeroshot": 4,
        "gpqa_main_zeroshot": 3,
        "gpqa_diamond_zeroshot": 1,
        "gpqa_diamond_cot_zeroshot": 1,
        "gpqa_extended_cot_zeroshot": 2,
        "gpqa_main_cot_zeroshot": 2,
        "sciq": 9,
        "agieval_sat_math": 86,
        "agieval_sat_en_without_passage": 1,
        "agieval_math": 18,
        "agieval_aqua_rat": 3,
        "commonsense_qa": 1,
        "arithmetic_3da": 4,
        "arithmetic_3ds": 38,
        "arithmetic_2ds": 23,
        "arithmetic_5ds": 6,
        "arithmetic_1dc": 5,
        "arithmetic_4ds": 4,
        "arithmetic_2dm": 181,
        "nq_open": 2,
        "triviaqa": 1
    },
    "proceedings.neurips.cc": {
        "count": 759,
        "gsm8k": 26,
        "agieval_math": 1,
        "arithmetic_5ds": 1,
        "arithmetic_5da": 1,
        "bbh_cot_fewshot_word_sorting": 2,
        "bbh_cot_fewshot_web_of_lies": 19,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 258,
        "bbh_cot_fewshot_tracking_shuffled_objects_seven_objects": 211,
        "bbh_cot_fewshot_tracking_shuffled_objects_five_objects": 226,
        "bbh_cot_fewshot_temporal_sequences": 2,
        "bbh_cot_fewshot_sports_understanding": 12
    },
    "brainly.ph": {
        "count": 726,
        "arc_challenge": 33,
        "arc_easy": 75,
        "headqa_en": 2,
        "gsm8k": 4,
        "mmlu_prehistory": 1,
        "mmlu_philosophy": 14,
        "mmlu_professional_psychology": 1,
        "mmlu_high_school_microeconomics": 7,
        "mmlu_high_school_macroeconomics": 2,
        "mmlu_security_studies": 3,
        "mmlu_human_aging": 2,
        "mmlu_miscellaneous": 12,
        "mmlu_marketing": 3,
        "mmlu_business_ethics": 2,
        "mmlu_professional_accounting": 2,
        "mmlu_medical_genetics": 1,
        "mmlu_college_medicine": 1,
        "mmlu_nutrition": 14,
        "mmlu_clinical_knowledge": 1,
        "mmlu_college_biology": 3,
        "mmlu_high_school_mathematics": 2,
        "mmlu_high_school_biology": 9,
        "mmlu_high_school_chemistry": 1,
        "mmlu_elementary_mathematics": 36,
        "mmlu_college_mathematics": 3,
        "mmlu_college_physics": 2,
        "mmlu_conceptual_physics": 7,
        "mmlu_college_chemistry": 1,
        "mmlu_astronomy": 2,
        "sciq": 10,
        "agieval_math": 3,
        "commonsense_qa": 1,
        "arithmetic_3da": 35,
        "arithmetic_3ds": 180,
        "arithmetic_4da": 2,
        "arithmetic_2ds": 25,
        "arithmetic_5da": 1,
        "arithmetic_1dc": 128,
        "arithmetic_4ds": 4,
        "arithmetic_2dm": 28,
        "arithmetic_2da": 52,
        "nq_open": 5,
        "triviaqa": 6
    },
    "nlp.cs.washington.edu": {
        "count": 689,
        "triviaqa": 689
    },
    "web2.0calc.com": {
        "count": 599,
        "mmlu_high_school_mathematics": 110,
        "agieval_sat_math": 2,
        "agieval_math": 423,
        "arithmetic_3da": 12,
        "arithmetic_3ds": 6,
        "arithmetic_2ds": 8,
        "arithmetic_1dc": 12,
        "arithmetic_4ds": 7,
        "arithmetic_2dm": 14,
        "arithmetic_2da": 5
    },
    "www.imdb.com": {
        "count": 563,
        "nq_open": 29,
        "triviaqa": 440,
        "bbh_cot_fewshot_web_of_lies": 2,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 8,
        "bbh_cot_fewshot_tracking_shuffled_objects_seven_objects": 32,
        "bbh_cot_fewshot_tracking_shuffled_objects_five_objects": 52
    },
    "quizizz.com": {
        "count": 511,
        "arc_challenge": 169,
        "arc_easy": 229,
        "gsm8k": 2,
        "mmlu_professional_law": 2,
        "mmlu_philosophy": 2,
        "mmlu_econometrics": 2,
        "mmlu_marketing": 1,
        "mmlu_high_school_statistics": 8,
        "mmlu_high_school_biology": 5,
        "mmlu_machine_learning": 5,
        "mmlu_elementary_mathematics": 32,
        "mmlu_conceptual_physics": 2,
        "mmlu_college_chemistry": 2,
        "mmlu_high_school_computer_science": 37,
        "agieval_sat_math": 4,
        "agieval_sat_en_without_passage": 6,
        "arithmetic_3ds": 1,
        "triviaqa": 2
    },
    "www.cliffsnotes.com": {
        "count": 470,
        "arc_challenge": 6,
        "arc_easy": 4,
        "headqa_en": 1,
        "gsm8k": 3,
        "mmlu_jurisprudence": 5,
        "mmlu_moral_disputes": 6,
        "mmlu_moral_scenarios": 18,
        "mmlu_high_school_world_history": 20,
        "mmlu_professional_law": 41,
        "mmlu_philosophy": 1,
        "mmlu_high_school_us_history": 14,
        "mmlu_logical_fallacies": 3,
        "mmlu_high_school_european_history": 8,
        "mmlu_international_law": 1,
        "mmlu_high_school_psychology": 10,
        "mmlu_professional_psychology": 2,
        "mmlu_high_school_microeconomics": 14,
        "mmlu_high_school_government_and_politics": 3,
        "mmlu_high_school_macroeconomics": 2,
        "mmlu_econometrics": 2,
        "mmlu_miscellaneous": 20,
        "mmlu_marketing": 10,
        "mmlu_business_ethics": 9,
        "mmlu_virology": 4,
        "mmlu_professional_accounting": 67,
        "mmlu_college_medicine": 1,
        "mmlu_management": 2,
        "mmlu_nutrition": 4,
        "mmlu_clinical_knowledge": 2,
        "mmlu_high_school_statistics": 7,
        "mmlu_college_biology": 1,
        "mmlu_high_school_mathematics": 1,
        "mmlu_high_school_biology": 20,
        "mmlu_anatomy": 11,
        "mmlu_high_school_chemistry": 4,
        "mmlu_machine_learning": 4,
        "mmlu_elementary_mathematics": 5,
        "mmlu_college_physics": 1,
        "mmlu_high_school_physics": 4,
        "mmlu_college_chemistry": 1,
        "mmlu_high_school_computer_science": 17,
        "mmlu_astronomy": 4,
        "gpqa_main_cot_n_shot": 1,
        "gpqa_extended_cot_n_shot": 1,
        "gpqa_extended_n_shot": 1,
        "gpqa_main_n_shot": 1,
        "gpqa_extended_generative_n_shot": 1,
        "gpqa_main_generative_n_shot": 1,
        "gpqa_extended_zeroshot": 1,
        "gpqa_main_zeroshot": 1,
        "gpqa_extended_cot_zeroshot": 1,
        "gpqa_main_cot_zeroshot": 1,
        "sciq": 2,
        "agieval_sat_math": 25,
        "agieval_sat_en_without_passage": 22,
        "agieval_math": 10,
        "agieval_lsat_ar": 16,
        "agieval_aqua_rat": 4,
        "arithmetic_3da": 2,
        "nq_open": 6,
        "triviaqa": 10
    },
    "adding.info": {
        "count": 423,
        "arithmetic_3da": 42,
        "arithmetic_2da": 381
    },
    "learninglink.oup.com": {
        "count": 419,
        "mmlu_jurisprudence": 67,
        "mmlu_prehistory": 28,
        "mmlu_philosophy": 26,
        "mmlu_formal_logic": 118,
        "mmlu_international_law": 35,
        "mmlu_world_religions": 33,
        "mmlu_security_studies": 36,
        "mmlu_business_ethics": 76
    },
    "www.vaia.com": {
        "count": 417,
        "arc_easy": 5,
        "headqa_en": 19,
        "mmlu_public_relations": 1,
        "mmlu_high_school_psychology": 7,
        "mmlu_professional_psychology": 3,
        "mmlu_high_school_microeconomics": 20,
        "mmlu_high_school_macroeconomics": 13,
        "mmlu_econometrics": 1,
        "mmlu_miscellaneous": 2,
        "mmlu_college_medicine": 1,
        "mmlu_nutrition": 3,
        "mmlu_clinical_knowledge": 1,
        "mmlu_high_school_statistics": 10,
        "mmlu_abstract_algebra": 6,
        "mmlu_college_biology": 1,
        "mmlu_high_school_mathematics": 5,
        "mmlu_high_school_biology": 16,
        "mmlu_high_school_chemistry": 24,
        "mmlu_elementary_mathematics": 3,
        "mmlu_college_mathematics": 5,
        "mmlu_college_physics": 23,
        "mmlu_college_computer_science": 1,
        "mmlu_conceptual_physics": 21,
        "mmlu_high_school_physics": 39,
        "mmlu_college_chemistry": 8,
        "mmlu_astronomy": 2,
        "gpqa_diamond_cot_n_shot": 5,
        "gpqa_main_cot_n_shot": 8,
        "gpqa_extended_cot_n_shot": 8,
        "gpqa_extended_n_shot": 8,
        "gpqa_main_n_shot": 8,
        "gpqa_diamond_n_shot": 5,
        "gpqa_extended_generative_n_shot": 8,
        "gpqa_diamond_generative_n_shot": 5,
        "gpqa_main_generative_n_shot": 7,
        "gpqa_extended_zeroshot": 7,
        "gpqa_main_zeroshot": 7,
        "gpqa_diamond_zeroshot": 4,
        "gpqa_diamond_cot_zeroshot": 5,
        "gpqa_extended_cot_zeroshot": 7,
        "gpqa_main_cot_zeroshot": 7,
        "sciq": 15,
        "agieval_math": 6,
        "agieval_aqua_rat": 1,
        "commonsense_qa": 1,
        "arithmetic_3ds": 29,
        "arithmetic_2ds": 2,
        "arithmetic_4ds": 3,
        "arithmetic_2dm": 14,
        "nq_open": 1,
        "triviaqa": 6
    },
    "math.stackexchange.com": {
        "count": 399,
        "mmlu_high_school_mathematics": 10,
        "mmlu_college_mathematics": 34,
        "agieval_sat_math": 4,
        "agieval_math": 265,
        "agieval_logiqa_en": 2,
        "agieval_aqua_rat": 1,
        "commonsense_qa": 1,
        "arithmetic_3ds": 2,
        "arithmetic_2ds": 6,
        "arithmetic_5ds": 1,
        "arithmetic_5da": 3,
        "arithmetic_1dc": 28,
        "arithmetic_4ds": 10,
        "arithmetic_2dm": 22,
        "arithmetic_2da": 1,
        "nq_open": 1,
        "triviaqa": 8
    },
    "content.randomhouse.com": {
        "count": 353,
        "mmlu_high_school_world_history": 20,
        "mmlu_high_school_european_history": 10,
        "mmlu_high_school_psychology": 145,
        "mmlu_high_school_microeconomics": 21,
        "mmlu_high_school_government_and_politics": 12,
        "mmlu_high_school_macroeconomics": 16,
        "mmlu_high_school_statistics": 58,
        "mmlu_high_school_biology": 13,
        "mmlu_high_school_chemistry": 30,
        "mmlu_high_school_physics": 28
    },
    "www.businessballs.com": {
        "count": 315,
        "triviaqa": 315
    },
    "www.doorsteptutor.com": {
        "count": 309,
        "mmlu_high_school_world_history": 20,
        "mmlu_high_school_european_history": 89,
        "mmlu_high_school_microeconomics": 34,
        "mmlu_high_school_macroeconomics": 40,
        "mmlu_high_school_statistics": 97,
        "mmlu_high_school_biology": 16,
        "mmlu_high_school_physics": 12,
        "arithmetic_3ds": 1
    },
    "www.coursesidekick.com": {
        "count": 308,
        "arc_challenge": 6,
        "arc_easy": 2,
        "headqa_en": 1,
        "gsm8k": 3,
        "mmlu_jurisprudence": 2,
        "mmlu_moral_disputes": 8,
        "mmlu_moral_scenarios": 1,
        "mmlu_high_school_world_history": 32,
        "mmlu_professional_law": 75,
        "mmlu_philosophy": 4,
        "mmlu_high_school_us_history": 12,
        "mmlu_high_school_european_history": 8,
        "mmlu_professional_psychology": 4,
        "mmlu_high_school_macroeconomics": 3,
        "mmlu_human_sexuality": 1,
        "mmlu_sociology": 1,
        "mmlu_econometrics": 6,
        "mmlu_human_aging": 1,
        "mmlu_marketing": 15,
        "mmlu_business_ethics": 36,
        "mmlu_professional_accounting": 25,
        "mmlu_nutrition": 2,
        "mmlu_professional_medicine": 8,
        "mmlu_high_school_statistics": 6,
        "mmlu_machine_learning": 1,
        "mmlu_elementary_mathematics": 2,
        "mmlu_high_school_physics": 3,
        "mmlu_high_school_computer_science": 9,
        "agieval_sat_en_without_passage": 21,
        "agieval_math": 1,
        "agieval_aqua_rat": 3,
        "arithmetic_4da": 1,
        "nq_open": 1,
        "triviaqa": 4
    },
    "artofproblemsolving.com": {
        "count": 293,
        "mmlu_high_school_mathematics": 12,
        "agieval_sat_math": 9,
        "agieval_math": 271,
        "agieval_aqua_rat": 1
    },
    "7sage.com": {
        "count": 290,
        "mmlu_professional_law": 13,
        "agieval_lsat_rc": 16,
        "agieval_lsat_lr": 19,
        "agieval_lsat_ar": 241,
        "agieval_logiqa_en": 1
    },
    "opentextbc.ca": {
        "count": 256,
        "sciq": 13,
        "agieval_sat_math": 1,
        "agieval_sat_en_without_passage": 1,
        "agieval_math": 1,
        "commonsense_qa": 1,
        "arithmetic_3ds": 232,
        "arithmetic_2ds": 2,
        "nq_open": 2,
        "triviaqa": 2,
        "bbh_cot_fewshot_snarks": 1
    },
    "www.ceneo.pl": {
        "count": 243,
        "polemo2_out": 243
    },
    "gmatclub.com": {
        "count": 237,
        "agieval_lsat_rc": 147,
        "agieval_lsat_lr": 59,
        "agieval_aqua_rat": 13,
        "arithmetic_3da": 1,
        "arithmetic_3ds": 4,
        "arithmetic_1dc": 1,
        "arithmetic_2dm": 5,
        "arithmetic_2da": 1,
        "groundcocoa": 6
    },
    "www.queryhome.com": {
        "count": 230,
        "triviaqa": 230
    },
    "www.vedantu.com": {
        "count": 202,
        "arc_easy": 5,
        "headqa_en": 14,
        "mmlu_prehistory": 1,
        "mmlu_international_law": 1,
        "mmlu_miscellaneous": 7,
        "mmlu_professional_accounting": 1,
        "mmlu_college_medicine": 8,
        "mmlu_nutrition": 2,
        "mmlu_clinical_knowledge": 7,
        "mmlu_college_biology": 3,
        "mmlu_high_school_mathematics": 1,
        "mmlu_high_school_biology": 10,
        "mmlu_high_school_chemistry": 7,
        "mmlu_electrical_engineering": 3,
        "mmlu_elementary_mathematics": 1,
        "mmlu_college_mathematics": 3,
        "mmlu_college_physics": 1,
        "mmlu_conceptual_physics": 7,
        "mmlu_high_school_physics": 7,
        "mmlu_college_chemistry": 7,
        "mmlu_astronomy": 3,
        "sciq": 9,
        "agieval_sat_math": 3,
        "agieval_math": 10,
        "agieval_aqua_rat": 2,
        "arithmetic_4da": 1,
        "arithmetic_2ds": 1,
        "arithmetic_1dc": 2,
        "arithmetic_2dm": 35,
        "nq_open": 14,
        "triviaqa": 26
    },
    "platinum-bench.csail.mit.edu": {
        "count": 201,
        "gsm8k": 101,
        "mmlu_high_school_mathematics": 95,
        "agieval_math": 5
    },
    "raw.githubusercontent.com": {
        "count": 196,
        "mmlu_professional_law": 19,
        "agieval_math": 1,
        "agieval_logiqa_en": 33,
        "triviaqa": 3,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 10,
        "bbh_cot_fewshot_tracking_shuffled_objects_seven_objects": 47,
        "bbh_cot_fewshot_tracking_shuffled_objects_five_objects": 83
    },
    "www.bartleby.com": {
        "count": 172,
        "arc_challenge": 11,
        "arc_easy": 9,
        "headqa_en": 1,
        "mmlu_moral_disputes": 7,
        "mmlu_professional_law": 9,
        "mmlu_high_school_us_history": 10,
        "mmlu_formal_logic": 1,
        "mmlu_high_school_european_history": 2,
        "mmlu_public_relations": 2,
        "mmlu_high_school_psychology": 1,
        "mmlu_professional_psychology": 2,
        "mmlu_high_school_microeconomics": 1,
        "mmlu_high_school_macroeconomics": 1,
        "mmlu_econometrics": 2,
        "mmlu_marketing": 4,
        "mmlu_professional_accounting": 3,
        "mmlu_global_facts": 1,
        "mmlu_nutrition": 3,
        "mmlu_clinical_knowledge": 2,
        "mmlu_high_school_statistics": 10,
        "mmlu_abstract_algebra": 1,
        "mmlu_high_school_biology": 8,
        "mmlu_high_school_chemistry": 4,
        "mmlu_electrical_engineering": 2,
        "mmlu_elementary_mathematics": 10,
        "mmlu_college_physics": 1,
        "mmlu_college_computer_science": 1,
        "mmlu_conceptual_physics": 41,
        "mmlu_high_school_physics": 2,
        "mmlu_high_school_computer_science": 5,
        "sciq": 3,
        "agieval_sat_math": 2,
        "agieval_math": 3,
        "commonsense_qa": 1,
        "arithmetic_3da": 1,
        "arithmetic_3ds": 1,
        "triviaqa": 4
    },
    "subtract.info": {
        "count": 160,
        "arithmetic_2ds": 160
    },
    "cdn.quizwise.com": {
        "count": 152,
        "triviaqa": 152
    },
    "www.studocu.vn": {
        "count": 151,
        "mmlu_public_relations": 46,
        "mmlu_econometrics": 59,
        "mmlu_business_ethics": 13,
        "gpqa_main_generative_n_shot": 1,
        "gpqa_extended_zeroshot": 1,
        "gpqa_main_zeroshot": 1,
        "gpqa_extended_cot_zeroshot": 1,
        "gpqa_main_cot_zeroshot": 1,
        "agieval_sat_math": 2,
        "agieval_sat_en_without_passage": 20,
        "arithmetic_3ds": 2,
        "triviaqa": 2,
        "bbh_cot_fewshot_word_sorting": 2
    },
    "www.oxen.ai": {
        "count": 146,
        "arc_challenge": 77,
        "gsm8k": 53,
        "mmlu_professional_law": 2,
        "mmlu_high_school_us_history": 7,
        "mmlu_high_school_european_history": 7
    },
    "queryhome.com": {
        "count": 142,
        "triviaqa": 142
    },
    "www.academia.edu": {
        "count": 141,
        "mmlu_econometrics": 12,
        "gpqa_diamond_cot_n_shot": 3,
        "gpqa_main_cot_n_shot": 4,
        "gpqa_extended_cot_n_shot": 4,
        "gpqa_extended_n_shot": 4,
        "gpqa_main_n_shot": 4,
        "gpqa_diamond_n_shot": 3,
        "gpqa_extended_generative_n_shot": 4,
        "gpqa_diamond_generative_n_shot": 3,
        "gpqa_main_generative_n_shot": 4,
        "gpqa_extended_zeroshot": 4,
        "gpqa_main_zeroshot": 4,
        "gpqa_diamond_zeroshot": 3,
        "gpqa_diamond_cot_zeroshot": 3,
        "gpqa_extended_cot_zeroshot": 4,
        "gpqa_main_cot_zeroshot": 4,
        "agieval_sat_math": 2,
        "agieval_sat_en_without_passage": 15,
        "agieval_lsat_rc": 8,
        "agieval_lsat_lr": 1,
        "agieval_lsat_ar": 10,
        "agieval_logiqa_en": 4,
        "agieval_aqua_rat": 3,
        "qasper_bool": 6,
        "triviaqa": 15,
        "groundcocoa": 1,
        "polemo2_out": 2,
        "polemo2_in": 7
    },
    "focusonlearningcenter.com": {
        "count": 139,
        "agieval_sat_math": 20,
        "agieval_sat_en": 12,
        "agieval_sat_en_without_passage": 107
    },
    "sidecu.culturameta.gov.co": {
        "count": 133,
        "arc_challenge": 16,
        "arc_easy": 38,
        "gsm8k": 1,
        "mmlu_jurisprudence": 2,
        "mmlu_moral_disputes": 2,
        "mmlu_professional_law": 6,
        "mmlu_philosophy": 5,
        "mmlu_high_school_psychology": 6,
        "mmlu_professional_psychology": 1,
        "mmlu_high_school_government_and_politics": 5,
        "mmlu_high_school_macroeconomics": 1,
        "mmlu_marketing": 1,
        "mmlu_professional_accounting": 9,
        "mmlu_management": 1,
        "mmlu_professional_medicine": 1,
        "mmlu_high_school_mathematics": 1,
        "mmlu_high_school_biology": 3,
        "mmlu_elementary_mathematics": 8,
        "mmlu_college_physics": 1,
        "mmlu_conceptual_physics": 3,
        "mmlu_high_school_physics": 2,
        "mmlu_high_school_computer_science": 13,
        "mmlu_astronomy": 1,
        "agieval_sat_math": 2,
        "agieval_math": 1,
        "arithmetic_2ds": 1,
        "arithmetic_4ds": 1,
        "nq_open": 1
    },
    "www.studystack.com": {
        "count": 126,
        "arc_challenge": 18,
        "arc_easy": 15,
        "mmlu_philosophy": 19,
        "mmlu_international_law": 3,
        "mmlu_high_school_geography": 1,
        "mmlu_high_school_psychology": 18,
        "mmlu_professional_psychology": 3,
        "mmlu_high_school_biology": 12,
        "mmlu_anatomy": 2,
        "mmlu_elementary_mathematics": 2,
        "mmlu_conceptual_physics": 21,
        "mmlu_astronomy": 4,
        "triviaqa": 8
    },
    "math.answers.com": {
        "count": 121,
        "arithmetic_2ds": 18,
        "arithmetic_2dm": 25,
        "arithmetic_2da": 62,
        "triviaqa": 16
    },
    "web.eecs.umich.edu": {
        "count": 120,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 120
    },
    "polwro.com": {
        "count": 120,
        "polemo2_out": 120
    },
    "forum.powerscore.com": {
        "count": 119,
        "agieval_lsat_lr": 89,
        "agieval_lsat_ar": 29,
        "arithmetic_4da": 1
    },
    "edurev.in": {
        "count": 116,
        "agieval_sat_math": 18,
        "agieval_sat_en": 12,
        "agieval_sat_en_without_passage": 39,
        "agieval_lsat_rc": 10,
        "arithmetic_3da": 3,
        "arithmetic_3ds": 4,
        "arithmetic_2ds": 1,
        "arithmetic_1dc": 7,
        "arithmetic_4ds": 1,
        "arithmetic_2dm": 16,
        "nq_open": 5
    },
    "www.jetpunk.com": {
        "count": 112,
        "triviaqa": 112
    },
    "proceedings.mlr.press": {
        "count": 112,
        "bbh_cot_fewshot_tracking_shuffled_objects_seven_objects": 48,
        "bbh_cot_fewshot_tracking_shuffled_objects_five_objects": 64
    },
    "d240jkaxprjasr.cloudfront.net": {
        "count": 109,
        "triviaqa": 109
    },
    "img.cracklsat.net": {
        "count": 103,
        "agieval_lsat_rc": 10,
        "agieval_lsat_lr": 20,
        "agieval_lsat_ar": 73
    },
    "easyllm.site": {
        "count": 99,
        "bbh_cot_fewshot_temporal_sequences": 99
    },
    "courses.lumenlearning.com": {
        "count": 98,
        "sciq": 78,
        "agieval_sat_math": 1,
        "agieval_math": 5,
        "commonsense_qa": 1,
        "arithmetic_3ds": 3,
        "nq_open": 6,
        "triviaqa": 4
    },
    "www.pasteurscube.com": {
        "count": 93,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 55,
        "bbh_cot_fewshot_tracking_shuffled_objects_five_objects": 38
    },
    "www.kaggle.com": {
        "count": 93,
        "gsm8k": 42,
        "mmlu_elementary_mathematics": 1,
        "sciq": 2,
        "agieval_math": 19,
        "agieval_aqua_rat": 2,
        "toxigen": 1,
        "triviaqa": 22,
        "bbh_cot_fewshot_temporal_sequences": 2,
        "groundcocoa": 2
    },
    "resources.finalsite.net": {
        "count": 92,
        "arc_easy": 9,
        "gsm8k": 12,
        "mmlu_high_school_world_history": 16,
        "mmlu_marketing": 1,
        "mmlu_high_school_statistics": 4,
        "mmlu_high_school_mathematics": 4,
        "mmlu_elementary_mathematics": 33,
        "agieval_math": 1,
        "arithmetic_3ds": 3,
        "arithmetic_5ds": 1,
        "arithmetic_5da": 1,
        "arithmetic_4ds": 1,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 2,
        "bbh_cot_fewshot_tracking_shuffled_objects_seven_objects": 1,
        "bbh_cot_fewshot_tracking_shuffled_objects_five_objects": 3
    },
    "www.wrexhamquizleague.co.uk": {
        "count": 89,
        "triviaqa": 89
    },
    "dokumen.pub": {
        "count": 89,
        "agieval_lsat_ar": 68,
        "triviaqa": 20,
        "polemo2_in": 1
    },
    "schoolbag.info": {
        "count": 88,
        "mmlu_high_school_psychology": 60,
        "mmlu_high_school_statistics": 11,
        "mmlu_high_school_physics": 17
    },
    "triyambak.org": {
        "count": 88,
        "mmlu_high_school_biology": 78,
        "gpqa_main_cot_n_shot": 1,
        "gpqa_extended_cot_n_shot": 1,
        "gpqa_extended_n_shot": 1,
        "gpqa_main_n_shot": 1,
        "gpqa_extended_generative_n_shot": 1,
        "gpqa_main_generative_n_shot": 1,
        "gpqa_extended_zeroshot": 1,
        "gpqa_main_zeroshot": 1,
        "gpqa_extended_cot_zeroshot": 1,
        "gpqa_main_cot_zeroshot": 1
    },
    "www.examtopics.com": {
        "count": 88,
        "mmlu_college_medicine": 15,
        "mmlu_professional_medicine": 35,
        "agieval_sat_math": 2,
        "agieval_sat_en_without_passage": 1,
        "agieval_lsat_rc": 20,
        "arithmetic_3da": 14,
        "arithmetic_3ds": 1
    },
    "valeur.com": {
        "count": 85,
        "arithmetic_2dm": 85
    },
    "www.bissoy.com": {
        "count": 84,
        "mmlu_high_school_psychology": 45,
        "mmlu_high_school_microeconomics": 14,
        "mmlu_high_school_chemistry": 21,
        "agieval_aqua_rat": 4
    },
    "studyx.ai": {
        "count": 84,
        "agieval_sat_math": 20,
        "arithmetic_3da": 25,
        "arithmetic_3ds": 30,
        "arithmetic_4da": 1,
        "arithmetic_2ds": 1,
        "arithmetic_4ds": 6,
        "arithmetic_2da": 1
    },
    "studylib.net": {
        "count": 84,
        "arc_challenge": 7,
        "arc_easy": 15,
        "mmlu_professional_law": 2,
        "mmlu_high_school_european_history": 2,
        "mmlu_high_school_psychology": 1,
        "mmlu_high_school_microeconomics": 1,
        "mmlu_human_aging": 2,
        "mmlu_professional_medicine": 2,
        "mmlu_high_school_statistics": 4,
        "mmlu_high_school_mathematics": 1,
        "mmlu_high_school_biology": 2,
        "mmlu_conceptual_physics": 5,
        "mmlu_high_school_physics": 1,
        "mmlu_high_school_computer_science": 12,
        "agieval_sat_en_without_passage": 25,
        "triviaqa": 2
    },
    "www.easynotecards.com": {
        "count": 80,
        "mmlu_high_school_biology": 80
    },
    "m.book118.com": {
        "count": 80,
        "agieval_gaokao_english": 80
    },
    "www.cambridge.org": {
        "count": 80,
        "mmlu_econometrics": 55,
        "agieval_sat_math": 2,
        "agieval_math": 6,
        "qasper_bool": 1,
        "arithmetic_3da": 8,
        "arithmetic_3ds": 1,
        "arithmetic_5ds": 1,
        "arithmetic_5da": 1,
        "triviaqa": 5
    },
    "www.percentagecal.com": {
        "count": 79,
        "arithmetic_3da": 79
    },
    "www.exampyq.com": {
        "count": 78,
        "mmlu_high_school_microeconomics": 46,
        "mmlu_high_school_macroeconomics": 32
    },
    "www.ck12.org": {
        "count": 78,
        "sciq": 44,
        "arithmetic_2ds": 1,
        "arithmetic_1dc": 7,
        "arithmetic_2dm": 5,
        "arithmetic_2da": 15,
        "nq_open": 1,
        "triviaqa": 5
    },
    "resources.quizalize.com": {
        "count": 75,
        "arc_challenge": 21,
        "arc_easy": 15,
        "mmlu_philosophy": 1,
        "mmlu_elementary_mathematics": 38
    },
    "www.proprofs.com": {
        "count": 75,
        "arc_challenge": 9,
        "arc_easy": 9,
        "mmlu_professional_law": 2,
        "mmlu_miscellaneous": 4,
        "mmlu_medical_genetics": 1,
        "mmlu_high_school_statistics": 12,
        "mmlu_high_school_biology": 8,
        "mmlu_anatomy": 2,
        "mmlu_elementary_mathematics": 17,
        "mmlu_college_computer_science": 2,
        "agieval_aqua_rat": 5,
        "arithmetic_3ds": 1,
        "arithmetic_2dm": 1,
        "triviaqa": 2
    },
    "neurips.cc": {
        "count": 75,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 16,
        "bbh_cot_fewshot_tracking_shuffled_objects_seven_objects": 26,
        "bbh_cot_fewshot_tracking_shuffled_objects_five_objects": 33
    },
    "psychologic.science": {
        "count": 74,
        "mmlu_high_school_psychology": 74
    },
    "issuu.com": {
        "count": 74,
        "triviaqa": 15,
        "bbh_cot_fewshot_web_of_lies": 1,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 1,
        "bbh_cot_fewshot_tracking_shuffled_objects_five_objects": 8,
        "bbh_cot_fewshot_temporal_sequences": 6,
        "bbh_cot_fewshot_sports_understanding": 2,
        "groundcocoa": 21,
        "polemo2_out": 4,
        "polemo2_in": 16
    },
    "lsathacks.com": {
        "count": 71,
        "agieval_lsat_lr": 17,
        "agieval_lsat_ar": 54
    },
    "typeset.io": {
        "count": 70,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 70
    },
    "www.quizballs.com": {
        "count": 68,
        "triviaqa": 68
    },
    "m.facebook.com": {
        "count": 67,
        "triviaqa": 16,
        "bbh_cot_fewshot_web_of_lies": 3,
        "bbh_cot_fewshot_temporal_sequences": 12,
        "groundcocoa": 35,
        "polemo2_in": 1
    },
    "flexbooks.ck12.org": {
        "count": 66,
        "arc_easy": 6,
        "gsm8k": 4,
        "mmlu_high_school_psychology": 1,
        "mmlu_college_biology": 2,
        "mmlu_elementary_mathematics": 3,
        "sciq": 48,
        "agieval_math": 2
    },
    "percent.info": {
        "count": 66,
        "arithmetic_3da": 43,
        "arithmetic_2da": 23
    },
    "www.another71.com": {
        "count": 64,
        "mmlu_professional_accounting": 64
    },
    "www.classace.io": {
        "count": 64,
        "arc_challenge": 8,
        "arc_easy": 23,
        "mmlu_professional_law": 2,
        "mmlu_philosophy": 2,
        "mmlu_miscellaneous": 2,
        "mmlu_professional_accounting": 1,
        "mmlu_management": 2,
        "mmlu_elementary_mathematics": 6,
        "mmlu_high_school_computer_science": 2,
        "arithmetic_3ds": 15,
        "nq_open": 1
    },
    "www.docsity.com": {
        "count": 63,
        "mmlu_professional_law": 31,
        "mmlu_high_school_psychology": 16,
        "mmlu_miscellaneous": 15,
        "arithmetic_4da": 1
    },
    "oldsite.nnu.edu": {
        "count": 62,
        "arc_easy": 7,
        "mmlu_professional_law": 8,
        "mmlu_philosophy": 1,
        "mmlu_formal_logic": 1,
        "mmlu_high_school_psychology": 4,
        "mmlu_marketing": 1,
        "mmlu_professional_accounting": 7,
        "mmlu_management": 2,
        "mmlu_high_school_mathematics": 8,
        "mmlu_high_school_biology": 1,
        "mmlu_high_school_chemistry": 1,
        "mmlu_elementary_mathematics": 3,
        "mmlu_high_school_computer_science": 2,
        "agieval_sat_en_without_passage": 3,
        "agieval_math": 12,
        "agieval_aqua_rat": 1
    },
    "slideplayer.com": {
        "count": 61,
        "arc_challenge": 22,
        "arc_easy": 10,
        "mmlu_moral_disputes": 2,
        "mmlu_professional_law": 4,
        "mmlu_philosophy": 2,
        "mmlu_high_school_european_history": 2,
        "mmlu_high_school_geography": 2,
        "mmlu_high_school_psychology": 1,
        "mmlu_high_school_microeconomics": 1,
        "mmlu_high_school_statistics": 2,
        "mmlu_elementary_mathematics": 4,
        "mmlu_college_mathematics": 1,
        "agieval_math": 5,
        "agieval_gaokao_english": 3
    },
    "bio.libretexts.org": {
        "count": 60,
        "sciq": 55,
        "nq_open": 3,
        "triviaqa": 2
    },
    "www.affordablecollegesolutions.com": {
        "count": 59,
        "agieval_sat_math": 18,
        "agieval_sat_en_without_passage": 41
    },
    "chem.libretexts.org": {
        "count": 58,
        "sciq": 48,
        "nq_open": 2,
        "triviaqa": 8
    },
    "www.solpass.org": {
        "count": 56,
        "arc_challenge": 13,
        "arc_easy": 43
    },
    "www.etutorworld.com": {
        "count": 55,
        "agieval_sat_en_without_passage": 55
    },
    "yamol.tw": {
        "count": 55,
        "agieval_gaokao_english": 55
    },
    "doe.louisiana.gov": {
        "count": 55,
        "mmlu_elementary_mathematics": 20,
        "agieval_sat_math": 5,
        "agieval_math": 13,
        "agieval_logiqa_en": 2,
        "agieval_gaokao_english": 4,
        "agieval_aqua_rat": 4,
        "arithmetic_3da": 3,
        "arithmetic_3ds": 3,
        "arithmetic_4ds": 1
    },
    "www.electrical4u.com": {
        "count": 54,
        "mmlu_electrical_engineering": 54
    },
    "es.scribd.com": {
        "count": 53,
        "mmlu_elementary_mathematics": 10,
        "gpqa_diamond_cot_n_shot": 2,
        "gpqa_main_cot_n_shot": 1,
        "gpqa_extended_cot_n_shot": 2,
        "gpqa_extended_n_shot": 2,
        "gpqa_main_n_shot": 2,
        "gpqa_diamond_n_shot": 2,
        "gpqa_extended_generative_n_shot": 2,
        "gpqa_diamond_generative_n_shot": 2,
        "gpqa_main_generative_n_shot": 2,
        "gpqa_extended_zeroshot": 2,
        "gpqa_main_zeroshot": 2,
        "gpqa_diamond_zeroshot": 2,
        "gpqa_diamond_cot_zeroshot": 2,
        "gpqa_extended_cot_zeroshot": 2,
        "gpqa_main_cot_zeroshot": 2,
        "agieval_sat_en_without_passage": 4,
        "agieval_aqua_rat": 7,
        "arithmetic_4ds": 3
    },
    "www.pearson.com": {
        "count": 53,
        "mmlu_high_school_biology": 17,
        "gpqa_diamond_cot_n_shot": 1,
        "gpqa_main_cot_n_shot": 1,
        "gpqa_extended_cot_n_shot": 1,
        "gpqa_extended_n_shot": 1,
        "gpqa_main_n_shot": 1,
        "gpqa_diamond_n_shot": 1,
        "gpqa_extended_generative_n_shot": 1,
        "gpqa_diamond_generative_n_shot": 1,
        "gpqa_main_generative_n_shot": 1,
        "gpqa_extended_zeroshot": 1,
        "gpqa_main_zeroshot": 1,
        "gpqa_diamond_zeroshot": 1,
        "gpqa_diamond_cot_zeroshot": 1,
        "gpqa_extended_cot_zeroshot": 1,
        "gpqa_main_cot_zeroshot": 1,
        "agieval_sat_math": 2,
        "agieval_math": 1,
        "arithmetic_3da": 3,
        "arithmetic_4ds": 1,
        "arithmetic_2dm": 1,
        "groundcocoa": 13
    },
    "nate9389.tistory.com": {
        "count": 52,
        "mmlu_college_biology": 13,
        "mmlu_college_physics": 39
    },
    "www.mathway.com": {
        "count": 52,
        "arithmetic_1dc": 45,
        "triviaqa": 7
    },
    "www.transtutors.com": {
        "count": 51,
        "mmlu_public_relations": 14,
        "mmlu_high_school_psychology": 11,
        "mmlu_professional_accounting": 12,
        "mmlu_high_school_statistics": 12,
        "agieval_sat_math": 1,
        "agieval_math": 1
    },
    "www.jyeoo.com": {
        "count": 51,
        "agieval_gaokao_english": 51
    },
    "www.cram.com": {
        "count": 50,
        "arc_easy": 9,
        "mmlu_moral_disputes": 6,
        "mmlu_philosophy": 3,
        "mmlu_high_school_geography": 1,
        "mmlu_professional_psychology": 12,
        "mmlu_high_school_macroeconomics": 1,
        "mmlu_miscellaneous": 12,
        "mmlu_high_school_biology": 2,
        "mmlu_astronomy": 4
    },
    "blog.sina.com.cn": {
        "count": 50,
        "agieval_gaokao_english": 50
    },
    "nces.ed.gov": {
        "count": 50,
        "arc_challenge": 10,
        "arc_easy": 4,
        "arithmetic_3da": 2,
        "arithmetic_4da": 9,
        "arithmetic_5ds": 3,
        "arithmetic_5da": 5,
        "arithmetic_4ds": 17
    },
    "pakmcqs.com": {
        "count": 50,
        "mmlu_sociology": 28,
        "mmlu_electrical_engineering": 18,
        "nq_open": 1,
        "triviaqa": 3
    },
    "www.answers.com": {
        "count": 50,
        "arc_challenge": 6,
        "arc_easy": 13,
        "mmlu_miscellaneous": 1,
        "mmlu_anatomy": 1,
        "mmlu_electrical_engineering": 1,
        "mmlu_elementary_mathematics": 1,
        "mmlu_conceptual_physics": 2,
        "nq_open": 2,
        "triviaqa": 23
    },
    "www.forum9.com": {
        "count": 50,
        "triviaqa": 50
    },
    "www.usmle.org": {
        "count": 49,
        "mmlu_professional_medicine": 49
    },
    "www.360doc.com": {
        "count": 49,
        "agieval_gaokao_english": 49
    },
    "www.baamboozle.com": {
        "count": 48,
        "arc_challenge": 6,
        "arc_easy": 12,
        "gsm8k": 6,
        "mmlu_nutrition": 1,
        "mmlu_elementary_mathematics": 21,
        "sciq": 1,
        "arithmetic_3da": 1
    },
    "practicequiz.com": {
        "count": 47,
        "arc_challenge": 27,
        "arc_easy": 20
    },
    "zhuanlan.zhihu.com": {
        "count": 47,
        "agieval_gaokao_english": 47
    },
    "www.turito.com": {
        "count": 47,
        "arc_easy": 5,
        "mmlu_high_school_geography": 1,
        "mmlu_elementary_mathematics": 2,
        "sciq": 3,
        "agieval_sat_math": 34,
        "agieval_aqua_rat": 1,
        "arithmetic_3da": 1
    },
    "s3-eu-west-1.amazonaws.com": {
        "count": 47,
        "mmlu_public_relations": 17,
        "mmlu_human_aging": 27,
        "agieval_math": 1,
        "triviaqa": 2
    },
    "derbyshirepubquizleague.wordpress.com": {
        "count": 47,
        "triviaqa": 47
    },
    "praxis.ets.org": {
        "count": 46,
        "mmlu_miscellaneous": 46
    },
    "www.hrexam.com": {
        "count": 46,
        "agieval_gaokao_english": 46
    },
    "www.geeksforgeeks.org": {
        "count": 46,
        "mmlu_college_computer_science": 15,
        "sciq": 1,
        "agieval_math": 5,
        "agieval_logiqa_en": 1,
        "agieval_aqua_rat": 2,
        "commonsense_qa": 2,
        "arithmetic_3ds": 3,
        "arithmetic_1dc": 3,
        "arithmetic_2dm": 2,
        "nq_open": 3,
        "triviaqa": 1,
        "bbh_cot_fewshot_tracking_shuffled_objects_five_objects": 8
    },
    "naukawpolsce.pl": {
        "count": 46,
        "polemo2_in": 46
    },
    "cdn2.hubspot.net": {
        "count": 45,
        "agieval_sat_en_without_passage": 45
    },
    "www.instagram.com": {
        "count": 45,
        "triviaqa": 16,
        "bbh_cot_fewshot_temporal_sequences": 5,
        "bbh_cot_fewshot_snarks": 3,
        "groundcocoa": 21
    },
    "www.sporcle.com": {
        "count": 44,
        "triviaqa": 44
    },
    "nos.netease.com": {
        "count": 43,
        "agieval_gaokao_english": 43
    },
    "www.cracksat.net": {
        "count": 42,
        "mmlu_high_school_physics": 33,
        "arithmetic_3da": 1,
        "arithmetic_2dm": 8
    },
    "people.tamu.edu": {
        "count": 41,
        "mmlu_philosophy": 41
    },
    "gateoverflow.in": {
        "count": 41,
        "mmlu_college_computer_science": 38,
        "agieval_math": 1,
        "arithmetic_2dm": 1,
        "nq_open": 1
    },
    "nnhsrasetti.pbworks.com": {
        "count": 40,
        "arc_challenge": 25,
        "arc_easy": 15
    },
    "www.yygrammar.com": {
        "count": 40,
        "agieval_gaokao_english": 40
    },
    "m.51jiaoxi.com": {
        "count": 40,
        "agieval_gaokao_english": 40
    },
    "www.sarthaks.com": {
        "count": 40,
        "mmlu_computer_security": 26,
        "gpqa_extended_cot_n_shot": 1,
        "gpqa_extended_n_shot": 1,
        "gpqa_extended_generative_n_shot": 1,
        "gpqa_extended_zeroshot": 1,
        "gpqa_extended_cot_zeroshot": 1,
        "agieval_math": 4,
        "arithmetic_2dm": 1,
        "nq_open": 4
    },
    "www.cs.cmu.edu": {
        "count": 40,
        "mmlu_machine_learning": 24,
        "arithmetic_4da": 2,
        "arithmetic_5ds": 3,
        "arithmetic_5da": 2,
        "arithmetic_4ds": 4,
        "triviaqa": 5
    },
    "www.britannica.com": {
        "count": 40,
        "triviaqa": 40
    },
    "core-docs.s3.amazonaws.com": {
        "count": 40,
        "arc_easy": 5,
        "gsm8k": 12,
        "mmlu_elementary_mathematics": 6,
        "agieval_aqua_rat": 1,
        "commonsense_qa": 1,
        "arithmetic_3da": 2,
        "arithmetic_3ds": 2,
        "arithmetic_5da": 5,
        "arithmetic_4ds": 2,
        "bbh_cot_fewshot_web_of_lies": 1,
        "bbh_cot_fewshot_tracking_shuffled_objects_five_objects": 3
    },
    "app.formative.com": {
        "count": 39,
        "mmlu_elementary_mathematics": 39
    },
    "m.kekenet.com": {
        "count": 39,
        "agieval_gaokao_english": 39
    },
    "openstax.org": {
        "count": 39,
        "sciq": 21,
        "agieval_math": 4,
        "arithmetic_3da": 7,
        "arithmetic_3ds": 4,
        "arithmetic_4ds": 1,
        "polemo2_out": 2
    },
    "reviewgamezone.com": {
        "count": 37,
        "arc_challenge": 12,
        "arc_easy": 23,
        "mmlu_professional_accounting": 2
    },
    "m.kaobei173.com": {
        "count": 37,
        "agieval_gaokao_english": 37
    },
    "gaokao.eol.cn": {
        "count": 37,
        "agieval_gaokao_english": 37
    },
    "www.varsitytutors.com": {
        "count": 37,
        "mmlu_professional_accounting": 24,
        "agieval_sat_math": 1,
        "agieval_math": 2,
        "arithmetic_3da": 1,
        "arithmetic_3ds": 1,
        "arithmetic_5ds": 1,
        "arithmetic_4ds": 3,
        "triviaqa": 4
    },
    "www.nysedregents.org": {
        "count": 37,
        "arc_challenge": 9,
        "arc_easy": 11,
        "mmlu_elementary_mathematics": 16,
        "bbh_cot_fewshot_sports_understanding": 1
    },
    "file.koolearn.com": {
        "count": 36,
        "agieval_gaokao_english": 36
    },
    "www.briarcliffschools.org": {
        "count": 35,
        "mmlu_high_school_world_history": 35
    },
    "www.test-questions.com": {
        "count": 35,
        "mmlu_professional_law": 35
    },
    "www.mbamcq.com": {
        "count": 35,
        "mmlu_management": 35
    },
    "www.thatquiz.org": {
        "count": 35,
        "mmlu_elementary_mathematics": 35
    },
    "launchpadeducation.com": {
        "count": 35,
        "agieval_sat_en_without_passage": 35
    },
    "issuhub.com": {
        "count": 34,
        "mmlu_high_school_psychology": 34
    },
    "m.zhangyue.com": {
        "count": 34,
        "agieval_gaokao_english": 34
    },
    "www.justanswer.com": {
        "count": 34,
        "mmlu_professional_law": 32,
        "arithmetic_3da": 1,
        "triviaqa": 1
    },
    "www.goodreads.com": {
        "count": 34,
        "triviaqa": 34
    },
    "www.tripadvisor.com": {
        "count": 34,
        "polemo2_in": 34
    },
    "practicetestgeeks.com": {
        "count": 33,
        "mmlu_professional_law": 33
    },
    "fiatlux-day.org": {
        "count": 33,
        "mmlu_high_school_psychology": 33
    },
    "www.gkqgykt.com": {
        "count": 33,
        "agieval_gaokao_english": 33
    },
    "hub.zenoml.com": {
        "count": 33,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 33
    },
    "www.preprints.org": {
        "count": 33,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 22,
        "bbh_cot_fewshot_tracking_shuffled_objects_seven_objects": 11
    },
    "medizzy.com": {
        "count": 32,
        "mmlu_professional_medicine": 32
    },
    "khsapstats.weebly.com": {
        "count": 32,
        "mmlu_high_school_statistics": 32
    },
    "www.cnenedu.com": {
        "count": 32,
        "agieval_gaokao_english": 32
    },
    "www.triviabug.com": {
        "count": 32,
        "triviaqa": 32
    },
    "hackmd.io": {
        "count": 31,
        "gsm8k": 31
    },
    "www.aplusebooks.com": {
        "count": 31,
        "mmlu_professional_law": 31
    },
    "www.exploredatabase.com": {
        "count": 31,
        "mmlu_machine_learning": 31
    },
    "www.physicsforums.com": {
        "count": 31,
        "mmlu_high_school_physics": 11,
        "gpqa_diamond_cot_n_shot": 1,
        "gpqa_main_cot_n_shot": 1,
        "gpqa_extended_cot_n_shot": 1,
        "gpqa_extended_n_shot": 1,
        "gpqa_main_n_shot": 1,
        "gpqa_diamond_n_shot": 1,
        "gpqa_extended_generative_n_shot": 1,
        "gpqa_diamond_generative_n_shot": 1,
        "gpqa_main_generative_n_shot": 1,
        "gpqa_extended_zeroshot": 1,
        "gpqa_main_zeroshot": 1,
        "gpqa_diamond_zeroshot": 1,
        "gpqa_diamond_cot_zeroshot": 1,
        "gpqa_extended_cot_zeroshot": 1,
        "gpqa_main_cot_zeroshot": 1,
        "agieval_math": 2,
        "toxigen": 1,
        "triviaqa": 2
    },
    "www.doe.mass.edu": {
        "count": 30,
        "arc_challenge": 12,
        "arc_easy": 18
    },
    "mcqmate.com": {
        "count": 30,
        "mmlu_marketing": 19,
        "mmlu_business_ethics": 11
    },
    "dfiles.jiajiaoban.com": {
        "count": 30,
        "agieval_gaokao_english": 30
    },
    "collegedunia.com": {
        "count": 30,
        "agieval_lsat_rc": 19,
        "arithmetic_3da": 1,
        "arithmetic_1dc": 9,
        "nq_open": 1
    },
    "compsciedu.com": {
        "count": 30,
        "mmlu_computer_security": 28,
        "nq_open": 2
    },
    "id.scribd.com": {
        "count": 30,
        "mmlu_professional_law": 26,
        "agieval_lsat_lr": 1,
        "arithmetic_4ds": 1,
        "triviaqa": 2
    },
    "ar5iv.labs.arxiv.org": {
        "count": 30,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 30
    },
    "blog.blueprintprep.com": {
        "count": 29,
        "mmlu_college_medicine": 29
    },
    "zonetech.in": {
        "count": 29,
        "mmlu_electrical_engineering": 29
    },
    "wk.baidu.com": {
        "count": 29,
        "agieval_gaokao_english": 29
    },
    "facrea.urosario.edu.co": {
        "count": 29,
        "mmlu_professional_law": 13,
        "agieval_math": 14,
        "arithmetic_5da": 1,
        "nq_open": 1
    },
    "genius.com": {
        "count": 29,
        "triviaqa": 29
    },
    "www.triviacountry.com": {
        "count": 29,
        "triviaqa": 29
    },
    "www.rynekzdrowia.pl": {
        "count": 29,
        "polemo2_in": 29
    },
    "laboratoria.net": {
        "count": 29,
        "polemo2_in": 29
    },
    "jhcee.cn": {
        "count": 28,
        "agieval_gaokao_english": 28
    },
    "21zujuan.21cnjy.com": {
        "count": 28,
        "agieval_gaokao_english": 28
    },
    "ui.adsabs.harvard.edu": {
        "count": 28,
        "qasper_bool": 28
    },
    "www.playfactile.com": {
        "count": 28,
        "mmlu_elementary_mathematics": 16,
        "triviaqa": 12
    },
    "s3.amazonaws.com": {
        "count": 28,
        "mmlu_high_school_psychology": 13,
        "agieval_sat_math": 2,
        "agieval_sat_en_without_passage": 7,
        "agieval_math": 2,
        "arithmetic_5da": 2,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 2
    },
    "benyoungmosesbrown.weebly.com": {
        "count": 27,
        "mmlu_high_school_statistics": 27
    },
    "www.k5learning.com": {
        "count": 27,
        "mmlu_elementary_mathematics": 26,
        "arithmetic_3ds": 1
    },
    "paperswithcode.com": {
        "count": 27,
        "qasper_bool": 25,
        "arithmetic_5ds": 1,
        "arithmetic_5da": 1
    },
    "www.nmet168.com": {
        "count": 26,
        "agieval_gaokao_english": 26
    },
    "m4maths.com": {
        "count": 26,
        "mmlu_college_mathematics": 11,
        "agieval_aqua_rat": 13,
        "arithmetic_3ds": 1,
        "arithmetic_4ds": 1
    },
    "www.examsegg.com": {
        "count": 26,
        "triviaqa": 26
    },
    "www.oakparkusd.org": {
        "count": 25,
        "mmlu_elementary_mathematics": 25
    },
    "opened.cuny.edu": {
        "count": 25,
        "sciq": 25
    },
    "www.floridabarexam.org": {
        "count": 24,
        "mmlu_professional_law": 24
    },
    "www.edinformatics.com": {
        "count": 24,
        "mmlu_elementary_mathematics": 24
    },
    "ultimatetestprep.com": {
        "count": 24,
        "agieval_sat_en_without_passage": 24
    },
    "101.201.118.170": {
        "count": 24,
        "agieval_gaokao_english": 24
    },
    "www.xiangpi.com": {
        "count": 24,
        "agieval_gaokao_english": 24
    },
    "download.s21i.co99.net": {
        "count": 24,
        "agieval_gaokao_english": 24
    },
    "www.quiz-zone.co.uk": {
        "count": 24,
        "triviaqa": 24
    },
    "erenow.org": {
        "count": 23,
        "mmlu_high_school_world_history": 23
    },
    "engineerscommunity.com": {
        "count": 23,
        "mmlu_electrical_engineering": 23
    },
    "mrkt.nnu.edu": {
        "count": 23,
        "mmlu_professional_law": 10,
        "agieval_sat_en_without_passage": 2,
        "agieval_math": 9,
        "agieval_aqua_rat": 1,
        "nq_open": 1
    },
    "www.examveda.com": {
        "count": 23,
        "mmlu_marketing": 19,
        "agieval_aqua_rat": 1,
        "nq_open": 1,
        "triviaqa": 2
    },
    "forum.another71.com": {
        "count": 22,
        "mmlu_professional_accounting": 22
    },
    "www.powerfulprep.com": {
        "count": 22,
        "agieval_sat_en_without_passage": 22
    },
    "www.battlefields.org": {
        "count": 22,
        "mmlu_high_school_us_history": 15,
        "nq_open": 5,
        "triviaqa": 2
    },
    "www.classtools.net": {
        "count": 22,
        "arc_challenge": 9,
        "arc_easy": 4,
        "webqs": 1,
        "gsm8k": 1,
        "mmlu_elementary_mathematics": 3,
        "triviaqa": 4
    },
    "artsandculture.google.com": {
        "count": 22,
        "mmlu_high_school_world_history": 12,
        "toxigen": 2,
        "triviaqa": 8
    },
    "www.triand.com": {
        "count": 21,
        "arc_challenge": 8,
        "arc_easy": 13
    },
    "www.mslaw.edu": {
        "count": 21,
        "mmlu_professional_law": 21
    },
    "gotouniv.s3.ap-south-1.amazonaws.com": {
        "count": 21,
        "agieval_sat_en_without_passage": 21
    },
    "mzujuan.xkw.com": {
        "count": 21,
        "agieval_gaokao_english": 21
    },
    "imgs.app.gaokaozhitongche.com": {
        "count": 21,
        "agieval_gaokao_english": 21
    },
    "www.wordplays.com": {
        "count": 21,
        "triviaqa": 21
    },
    "www.znanylekarz.pl": {
        "count": 21,
        "polemo2_in": 21
    },
    "apushpsychos.weebly.com": {
        "count": 20,
        "mmlu_high_school_us_history": 20
    },
    "people.musc.edu": {
        "count": 20,
        "mmlu_virology": 20
    },
    "study.sagepub.com": {
        "count": 20,
        "mmlu_medical_genetics": 20
    },
    "physics-problems-solutions.blogspot.com": {
        "count": 20,
        "mmlu_college_physics": 20
    },
    "danstestprep.com": {
        "count": 20,
        "agieval_sat_en_without_passage": 20
    },
    "www.matermiddlehigh.org": {
        "count": 20,
        "agieval_sat_en_without_passage": 20
    },
    "www.testbest.com": {
        "count": 20,
        "agieval_lsat_ar": 20
    },
    "www.slideshare.net": {
        "count": 20,
        "triviaqa": 10,
        "bbh_cot_fewshot_word_sorting": 4,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 3,
        "bbh_cot_fewshot_temporal_sequences": 2,
        "polemo2_in": 1
    },
    "dromersenturk.com": {
        "count": 19,
        "mmlu_professional_medicine": 19
    },
    "www.physicslab.org": {
        "count": 19,
        "arc_challenge": 10,
        "arc_easy": 7,
        "mmlu_high_school_physics": 2
    },
    "pressbooks.bccampus.ca": {
        "count": 19,
        "sciq": 17,
        "agieval_math": 2
    },
    "www.semanticscholar.org": {
        "count": 19,
        "qasper_bool": 19
    },
    "open.spotify.com": {
        "count": 19,
        "nq_open": 16,
        "triviaqa": 3
    },
    "quizglobal.com": {
        "count": 19,
        "triviaqa": 19
    },
    "pa01916442.schoolwires.net": {
        "count": 18,
        "mmlu_high_school_statistics": 18
    },
    "community.csusm.edu": {
        "count": 18,
        "mmlu_elementary_mathematics": 18
    },
    "www.ridgewood.k12.oh.us": {
        "count": 18,
        "mmlu_elementary_mathematics": 18
    },
    "www.ucolick.org": {
        "count": 18,
        "mmlu_astronomy": 18
    },
    "xiangpi.com": {
        "count": 18,
        "agieval_gaokao_english": 18
    },
    "sciyard.com": {
        "count": 18,
        "agieval_gaokao_english": 18
    },
    "www.slideserve.com": {
        "count": 18,
        "arc_challenge": 8,
        "arc_easy": 5,
        "mmlu_elementary_mathematics": 1,
        "mmlu_conceptual_physics": 1,
        "agieval_math": 2,
        "arithmetic_3da": 1
    },
    "www.cymath.com": {
        "count": 18,
        "arithmetic_1dc": 18
    },
    "triviabug.com": {
        "count": 18,
        "triviaqa": 18
    },
    "triviabliss.com": {
        "count": 18,
        "triviaqa": 18
    },
    "core-docs.s3.us-east-1.amazonaws.com": {
        "count": 18,
        "mmlu_elementary_mathematics": 10,
        "arithmetic_5ds": 1,
        "arithmetic_5da": 4,
        "bbh_cot_fewshot_tracking_shuffled_objects_seven_objects": 3
    },
    "jcesom.marshall.edu": {
        "count": 17,
        "mmlu_professional_medicine": 17
    },
    "cdn.kastatic.org": {
        "count": 17,
        "agieval_sat_en_without_passage": 17
    },
    "mtiku.21cnjy.com": {
        "count": 17,
        "agieval_gaokao_english": 17
    },
    "specialties.bayt.com": {
        "count": 17,
        "mmlu_professional_accounting": 14,
        "triviaqa": 3
    },
    "bpsscience.weebly.com": {
        "count": 16,
        "arc_easy": 16
    },
    "accreditation.prsa.org": {
        "count": 16,
        "mmlu_public_relations": 16
    },
    "www.leonschools.net": {
        "count": 16,
        "mmlu_high_school_macroeconomics": 16
    },
    "www.studyadda.com": {
        "count": 16,
        "arc_easy": 10,
        "mmlu_electrical_engineering": 4,
        "mmlu_elementary_mathematics": 2
    },
    "www.ctcexams.nesinc.com": {
        "count": 16,
        "mmlu_elementary_mathematics": 16
    },
    "mathematicsgre.com": {
        "count": 16,
        "mmlu_college_mathematics": 16
    },
    "www.asksia.ai": {
        "count": 16,
        "mmlu_college_mathematics": 16
    },
    "ks3-cn-guangzhou.ksyun.com": {
        "count": 16,
        "agieval_gaokao_english": 16
    },
    "edu.newdu.com": {
        "count": 16,
        "agieval_gaokao_english": 16
    },
    "free.eol.cn": {
        "count": 16,
        "agieval_gaokao_english": 16
    },
    "zhidao.baidu.com": {
        "count": 16,
        "agieval_gaokao_english": 16
    },
    "ft.huijiaoyun.com": {
        "count": 16,
        "agieval_gaokao_english": 16
    },
    "www.cpsenglish.com": {
        "count": 16,
        "agieval_gaokao_english": 16
    },
    "qhgjzx.jnjy.net.cn": {
        "count": 16,
        "agieval_gaokao_english": 16
    },
    "www.sciyard.com": {
        "count": 16,
        "agieval_gaokao_english": 16
    },
    "basic.ah.smartedu.cn": {
        "count": 16,
        "agieval_gaokao_english": 16
    },
    "www.ahedu.cn": {
        "count": 16,
        "agieval_gaokao_english": 16
    },
    "qisu.qisuen.cn": {
        "count": 16,
        "agieval_gaokao_english": 16
    },
    "bbs.bigear.cn": {
        "count": 16,
        "agieval_gaokao_english": 16
    },
    "mastermindclub1978.com": {
        "count": 16,
        "triviaqa": 16
    },
    "www.sfquiz.org.uk": {
        "count": 16,
        "triviaqa": 16
    },
    "mcqtimes.com": {
        "count": 15,
        "mmlu_sociology": 15
    },
    "education.stvincent.edu": {
        "count": 15,
        "mmlu_miscellaneous": 15
    },
    "web.utk.edu": {
        "count": 15,
        "mmlu_professional_accounting": 15
    },
    "www.actexam.net": {
        "count": 15,
        "mmlu_high_school_mathematics": 15
    },
    "www.rider.edu": {
        "count": 14,
        "mmlu_miscellaneous": 14
    },
    "pedroramos.web.uah.es": {
        "count": 14,
        "mmlu_elementary_mathematics": 14
    },
    "1.tiku.cn": {
        "count": 14,
        "agieval_gaokao_english": 14
    },
    "m.inf.qq.com": {
        "count": 14,
        "agieval_gaokao_english": 14
    },
    "www.quia.com": {
        "count": 14,
        "arc_easy": 6,
        "mmlu_high_school_psychology": 2,
        "nq_open": 1,
        "triviaqa": 5
    },
    "www.thefreedictionary.com": {
        "count": 14,
        "triviaqa": 14
    },
    "www.inyourarea.co.uk": {
        "count": 14,
        "triviaqa": 14
    },
    "www.danword.com": {
        "count": 14,
        "triviaqa": 14
    },
    "www.ncbex.org": {
        "count": 13,
        "mmlu_professional_law": 13
    },
    "fl01903265.schoolwires.net": {
        "count": 13,
        "mmlu_high_school_macroeconomics": 13
    },
    "www.gace.ets.org": {
        "count": 13,
        "mmlu_miscellaneous": 13
    },
    "runestone.academy": {
        "count": 13,
        "mmlu_high_school_computer_science": 13
    },
    "www.csp.nyc": {
        "count": 13,
        "mmlu_high_school_computer_science": 13
    },
    "www.tutelaprep.com": {
        "count": 13,
        "agieval_sat_en_without_passage": 13
    },
    "forums.spacebattles.com": {
        "count": 13,
        "agieval_lsat_ar": 12,
        "commonsense_qa": 1
    },
    "www.thefreelibrary.com": {
        "count": 13,
        "triviaqa": 13
    },
    "twitter.com": {
        "count": 13,
        "triviaqa": 13
    },
    "pfannenstielhistory.weebly.com": {
        "count": 12,
        "mmlu_high_school_world_history": 12
    },
    "www2.tesu.edu": {
        "count": 12,
        "mmlu_public_relations": 12
    },
    "css.csail.mit.edu": {
        "count": 12,
        "mmlu_computer_security": 12
    },
    "www.aama-ntl.org": {
        "count": 12,
        "mmlu_anatomy": 12
    },
    "www.education.ne.gov": {
        "count": 12,
        "mmlu_elementary_mathematics": 12
    },
    "rhsdashboard.weebly.com": {
        "count": 12,
        "agieval_sat_en": 12
    },
    "www.cheenta.com": {
        "count": 12,
        "agieval_math": 12
    },
    "lsatblog.blogspot.com": {
        "count": 12,
        "agieval_lsat_ar": 12
    },
    "www.qxwxw.com": {
        "count": 12,
        "agieval_gaokao_english": 12
    },
    "html.study.yanxiu.jsyxsq.com": {
        "count": 12,
        "agieval_gaokao_english": 12
    },
    "www.sfbroad.com": {
        "count": 12,
        "agieval_gaokao_english": 12
    },
    "www.poetryfoundation.org": {
        "count": 12,
        "triviaqa": 12
    },
    "d3pbdxdl8c65wb.cloudfront.net": {
        "count": 12,
        "triviaqa": 12
    },
    "pubquizquestions.net": {
        "count": 12,
        "triviaqa": 12
    },
    "freequizdatabase.weebly.com": {
        "count": 12,
        "triviaqa": 12
    },
    "lmql.ai": {
        "count": 12,
        "bbh_cot_fewshot_tracking_shuffled_objects_three_objects": 12
    },
    "www.mp.pl": {
        "count": 12,
        "polemo2_in": 12
    },
    "www.mgu.ac.in": {
        "count": 11,
        "mmlu_econometrics": 11
    },
    "www.fsmb.org": {
        "count": 11,
        "mmlu_professional_medicine": 11
    },
    "2.files.edl.io": {
        "count": 11,
        "mmlu_high_school_statistics": 11
    },
    "www.edit95.com": {
        "count": 11,
        "mmlu_college_biology": 11
    },
    "www.thinkinglsat.com": {
        "count": 11,
        "agieval_lsat_ar": 11
    },
    "m.ht88.com": {
        "count": 11,
        "agieval_gaokao_english": 11
    },
    "quiz-zone.co.uk": {
        "count": 11,
        "triviaqa": 11
    },
    "quizzclub.com": {
        "count": 11,
        "triviaqa": 11
    },
    "www.amazon.com": {
        "count": 11,
        "triviaqa": 11
    },
    "www.steadyrun.com": {
        "count": 11,
        "triviaqa": 11
    },
    "www.jpost.com": {
        "count": 11,
        "triviaqa": 11
    },
    "www.questionai.com": {
        "count": 10,
        "arc_challenge": 8,
        "arc_easy": 1,
        "headqa_en": 1
    },
    "sde.uoc.ac.in": {
        "count": 10,
        "mmlu_philosophy": 10
    },
    "www.psy.vanderbilt.edu": {
        "count": 10,
        "mmlu_human_sexuality": 10
    },
    "www.chettinadtech.ac.in": {
        "count": 10,
        "mmlu_management": 10
    },
    "exambank.mmust.ac.ke": {
        "count": 10,
        "mmlu_nutrition": 10
    },
    "farleymath.weebly.com": {
        "count": 10,
        "mmlu_high_school_statistics": 10
    },
    "gtu-mcq.com": {
        "count": 10,
        "mmlu_electrical_engineering": 10
    },
    "www.edevaluation.com": {
        "count": 10,
        "mmlu_elementary_mathematics": 10
    },
    "www.alfredsolis.org": {
        "count": 10,
        "mmlu_elementary_mathematics": 10
    },
    "www.helpteaching.com": {
        "count": 10,
        "mmlu_elementary_mathematics": 10
    },
    "www.ms890.org": {
        "count": 10,
        "mmlu_elementary_mathematics": 10
    },
    "apclassroom.collegeboard.org": {
        "count": 10,
        "mmlu_high_school_computer_science": 10
    },
    "cdn.revolutionprep.com": {
        "count": 10,
        "agieval_sat_en_without_passage": 10
    },
    "www.secexams.com": {
        "count": 10,
        "agieval_lsat_rc": 10
    },
    "player.uacdn.net": {
        "count": 10,
        "agieval_lsat_rc": 10
    },
    "image.sunedu.com": {
        "count": 10,
        "agieval_gaokao_english": 10
    },
    "www.newsday.com": {
        "count": 10,
        "agieval_gaokao_english": 10
    },
    "placement.freshersworld.com": {
        "count": 10,
        "agieval_aqua_rat": 10
    },
    "www.pressreader.com": {
        "count": 10,
        "triviaqa": 10
    },
    "www.brainyquote.com": {
        "count": 10,
        "triviaqa": 10
    },
    "microsoft.github.io": {
        "count": 10,
        "bbh_cot_fewshot_sports_understanding": 10
    },
    "colab.research.google.com": {
        "count": 10,
        "bbh_cot_fewshot_sports_understanding": 10
    },
    "mcdowellscienceexam.weebly.com": {
        "count": 8,
        "arc_easy": 8
    },
    "michaelynaucoin.weebly.com": {
        "count": 8,
        "arc_easy": 8
    },
    "sendy.bibliocad.com": {
        "count": 7,
        "arc_easy": 7
    },
    "triand.com": {
        "count": 7,
        "arc_easy": 5,
        "mmlu_elementary_mathematics": 2
    },
    "www.gimkit.com": {
        "count": 6,
        "arc_easy": 6
    },
    "nnhstigerscience.weebly.com": {
        "count": 5,
        "arc_easy": 5
    }
}